{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entry 48 - Decision Tree Impurity Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "Impurity seems like it should be a simple calculation. However, depending on prevalence of classes and quirks in the data, it's usually not as straight forward as it sounds.\n",
    "\n",
    "To demonstrate the challenge, let's pretend we're trying to identify twitter posts that were written by a bot. During an analysis of the data, we noticed that bots tend to use specific words or groups of words that humans don't. As such, we want to use n-grams to pull out these individual and grouped words.\n",
    "\n",
    "### Example\n",
    "\n",
    "#### Context\n",
    "\n",
    "To create an *n-gram* you break a sentence, paragraph, or text document into managable chunks where common words, punctuation, and capitalization have been removed. For example, if we start with the sentence \"The quick, brown fox jumped over the fence.\", first we'd strip out \"the\", replace any uppercase letters with lowercase, and get rid of the punctuation to end up with  \"quick brown fox jumped over fence\".\n",
    "\n",
    "Next we'd break it into chucks, which gives us a list, the length of which depends on how many words are included in a chunk:\n",
    "\n",
    "  - *unigram*: Treating each word as it's own chunk\n",
    "    - Example: [\"quick\", \"brown\", \"fox\", \"jumped\", \"over\", \"fence\"]\n",
    "  - *bigram*: Grouping sets of two words together as a chunk\n",
    "    - Example: [\"quick brown\", \"brown fox\", \"fox jumped\", \"jumped over\", \"over fence\"]\n",
    "  - *trigram*: Grouping sets of two words together as a chunk\n",
    "    - Example: [\"quick brown fox\", \"brown fox jumped\", \"fox jumped over\", \"jumped over fence\"]\n",
    "  - *n-gram*: This chunking/grouping can be done with any number of words: 4, 5, 6, or more. As such, the generic term referring to any given number of chunks is *n-gram*\n",
    "\n",
    "#### Results\n",
    "\n",
    "Let's say we want to identify the unigrams that are most likely written by a bot, but only want to record the *most* bot-like word for any single tweet. Our pretend analysis returned 3 good candidates for one tweet:\n",
    "\n",
    "- \"abort\"\n",
    "  - 35 total uses\n",
    "    - 29 bot uses\n",
    "    - 6 human uses\n",
    "  - 82.86% bot usage\n",
    "- \"terminate\"\n",
    "  - 5 total uses\n",
    "    - 5 bot uses\n",
    "    - 0 human uses\n",
    "  - 100% bot usage\n",
    "- \"submit\"\n",
    "  - 45 total uses\n",
    "    - 30 bot uses\n",
    "    - 15 human uses\n",
    "  - 66.66% bot usage\n",
    "\n",
    "If we choose to use the metric of the word that is most used by bots we end up with \"submit\", but that word has the worst ratio of bot to human usage. If we pick the word with the higest percentage of bot usage we end up with \"terminate\", which is used least frequently in our overall dataset and is less likely to be useful.\n",
    "\n",
    "What we'd really want for our metric is something that balances the percentage with the frequency of use and would return \"abort\" as our most bot-like result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Options\n",
    "\n",
    "There are several different impurity measures for each type of decision tree:\n",
    "\n",
    "### `DecisionTreeClassifier`\n",
    "\n",
    "- **Default**: gini impurity\n",
    "  - From page 234 of *Machine Learning with Python Cookbook*\n",
    "    - $G(t) = 1 - \\displaystyle\\sum_{i=1}^{c} P_{i}^2$\n",
    "    - Where\n",
    "      - $G(t)$: gini impurity at node $t$\n",
    "      - $t$: a specific node\n",
    "      - $c$: class\n",
    "      - $P_{i}$: proportion of observations of class $c$ at node $t$\n",
    "  - From page 177 of *Hands-On Machine Learning*\n",
    "    - $G_{i} = 1 - \\displaystyle\\sum_{k=1}^{n} P_{i,k}^2$\n",
    "    - Where\n",
    "      - $G_{i}$: gini impurity at node $i$\n",
    "      - $i$: a specific node\n",
    "      - $k$: class\n",
    "      - $P_{i, k}^2$: the raio of class $k$ instances among the training instances of node $i$\n",
    "   - The trick to understanding gini impurity is to realize that the calculation is done with the numbers in `samples` and `values`\n",
    "     - Example: Take the green setosa class node at depth 2\n",
    "       - Samples = 44\n",
    "       - Values = [0, 39, 5]\n",
    "       - Gini = $1 - \\frac{0}{44}^2 - \\frac{39}{44}^2 - \\frac{5}{44}^2 \\approx 0.201$\n",
    "   - Reading Gini impurity\n",
    "     - A Gini impurity of 0 means that the node is pure\n",
    "       - Example: If all the samples in the green setosa class node at depth 2 was in fact setosa we'd get: $1 - \\frac{44}{44} = 1 - 1 = 0$\n",
    "     - The closer the Gini impurity is to 1 the more impure (i.e. mixed) it is.\n",
    "       - Example: If the classes in the green setosa class node at depth 2 were in fact evenly split we'd get: $1 - \\frac{15}{45} - \\frac{15}{45} - \\frac{15}{45} \\approx 0.67$\n",
    "- **Alternate**: entropy\n",
    "  - Per page 180 of *Hands-On Machine Learning*: \"originated in thermodynamics as a measure of molecular disorder; entropy approaches zero when molecules are sill and well ordered.\"\n",
    "  - A value of 0 means all samples belong to the same class (i.e. node is pure)\n",
    "  - Higher values mean there is more mixing of the classes (i.e. node has higher impurity)\n",
    "  - Similar to Gini Impurity, but includes a log component instead of a squared component\n",
    "  - From page 181 of *Hands-On Machine Learning*\n",
    "    - $H_{i} = - \\displaystyle\\sum_{\\substack{k=1\\\\ P_{i, k} \\neq 0}}^{n} P_{i, k} log_{2}(P_{i, k})$\n",
    "\n",
    "### `DecisionTreeRegressor`\n",
    "\n",
    "- **Default**: MSE (mean squared error)\n",
    "- **Alternates**\n",
    "  - Friedman MSE (MSE plus Friedmanâ€™s improvement score for potential splits)\n",
    "  - MAE (mean absolute error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Proposed Solution\n",
    "\n",
    "This part is easy, default values have already been provided for both the Classifier and Regressor versions of Decision Trees in Scikit Learn.\n",
    "\n",
    "*Hands-On Machine Learning* provides some context on the differences for Classification Trees on page 181: \n",
    "  - Using Gini or Entropy usually leads to similar trees\n",
    "  - Gini is slightly faster to compute\n",
    "  - When results are different\n",
    "    - Gini impurity tends to isolate the most frequent class in its own branch\n",
    "    - Entropy produces slightly more balanced trees\n",
    "\n",
    "For nuanced comparisons between the different regression metrics, check out Entries [21](https://julielinx.github.io/blog/21_reg_score_theory/) and [22](https://julielinx.github.io/blog/22_reg_score_implement/) which both talk about scoring regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "Analyzing Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Machine Learning with Python Cookbook](https://www.amazon.com/Machine-Learning-Python-Cookbook-Preprocessing/dp/1491989386)\n",
    "- [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646)\n",
    "- [Entropy: How Decision Trees Make Decisions](https://towardsdatascience.com/entropy-how-decision-trees-make-decisions-2946b9c18c8)\n",
    "- [Decision Tree Classification in Python](https://www.datacamp.com/community/tutorials/decision-tree-classification-python)\n",
    "- [1.10.7. Mathematical formulation](https://scikit-learn.org/stable/modules/tree.html#mathematical-formulation)\n",
    "- [Entry 21: Scoring Regression Models - Theory](https://julielinx.github.io/blog/21_reg_score_theory/)\n",
    "- [Entry 22: Scoring Regression models - Implementation](https://julielinx.github.io/blog/22_reg_score_implement/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
