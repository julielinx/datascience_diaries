{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entry 49 - Decision Trees Analysis and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "One of the major benefits of using Decision Trees is their interpretability. To take advantage of this benefit, you need to know how to pull out the information in a usable way.\n",
    "\n",
    "One of the major challanges of Decision Trees is the propensity to overfit. To address this challenge, you need to know if there are any indicators of overfitting, when a tree may need to be pruned, or whether there are features with information that wouldn't be available when predicting on new data.\n",
    "\n",
    "I'm also interested in ways to compare trees to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Options\n",
    "\n",
    "### Scoring Metrics\n",
    "\n",
    "The obvious place to start is with the scoring metrics I discussed back in Entries [23](https://julielinx.github.io/blog/23_class_score_theory/) and [24](https://julielinx.github.io/blog/24_class_score_implement/). Using the [Entry 24 notebook](https://github.com/julielinx/datascience_diaries/blob/master/02_model_eval/24_nb_class_score_implement.ipynb) I was able to quickly throw together a function that returned 10 scoring metrics for several cross validated versions of a model.\n",
    "\n",
    "It's kinda fun to come back to old code and turn what had been a hard coded solution into a single function. I also combined the scoring metrics that are available with a couple of the ones I used the `make_scorer` function to write.\n",
    "\n",
    "So that gives me a way to rate a model and cross validate it. However, I also want to be able to look at some metrics around a single tree.\n",
    "\n",
    "### Feature Importance\n",
    "\n",
    "Feature importance is a value that gives you an idea of how important a specific feature is in the Decision Tree. All values are between 0 and 1. A value of 0 is no contribution and a value of 1 is perfect contribution. Values closer to 1 are less likely as all values add up to 1. *Side note*, if the value is 1 then that feature is probably *data leakage*.\n",
    "\n",
    "*Data leakage* is when information from the target variable is inappropriately captured in another feature. An example would be if the facility id in a cancer dataset perfectly predicted whether a patient lived or died within 5 years of diagnosis. This happened during a Data Science competition, the root cause of the facility id predicting longevity so well was that the facilities took different kinds of cancer or different stages of cancer. Some of those cancers or conditions were much more leathal than others.\n",
    "\n",
    "Page 180 of [Applied Predictive Modeling](https://www.amazon.com/Applied-Predictive-Modeling-Max-Kuhn-ebook/dp/B00K15TZU0) points out one of the practicalities of features with higher importance:\n",
    "\n",
    "> Intuitively, predictors that appear higher in the tree (i.e., earlier splits) or those that appear multiple times in the tree will be more important than predictors that occur lower in the tree or not at all.\n",
    "\n",
    "The `.feature_importance_` method returns the feature importance values for us. \n",
    "\n",
    "When initially looking at the results they seem to return the same information for trees that coefficients do for linear models. However, whereas coefficients in linear models are positive or negative, indicating if they contribute toward positively identifying or negatively disqualifying a feature, all feature importance values are positive.\n",
    "\n",
    "This means that feature importance doesn't tell you which class the feature is important for (\"survived\" vs \"died\") or how that feature is informative (high, low, etc). \n",
    "\n",
    "<img src='images/49a_feature_importance.png'>\n",
    "\n",
    "As discussed in [Entry 44]() Decision Trees automatically perform feature selection, meaning that not all features are used (i.e. they have an importance of 0). To make the results of `.feature_importance_` more readable in the notebook, I removed the features that weren't used, then listed the remaining features in order. As a final touch, I threw the values for the used features into a horizontal bar chart.\n",
    "\n",
    "### Tree and Node Metrics\n",
    "\n",
    "While working on [Entry 47](), I looked at a series of metrics around the depth, number of leaves, and the impurity and sample size at the split and leaf levels. The `tree.tree_` method holds several of these full tree metrics including depth, number of nodes, number of leaves, number of classes, and number of features. It also includes several arrays of information on the impurity, sample size, and thresholds.\n",
    "\n",
    "Combining this information with some edited code from Scikit Learn's [Understanding the decision tree structure](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#), I was able to grab the min, max, mean, median, and standard deviation of the basic metrics I'd looked at in [Entry 47]().\n",
    "\n",
    "Using these metrics I can see if the tree trained until all nodes were pure (all leaves have a Gini value of 0), how deep the tree goes, what features are important in the Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Proposed Solution\n",
    "\n",
    "Between the scoring metrics, feature importance information, and tree and node metrics I was able to compile a comprehensive view of a tree. These allow me to make informed decisions on whether the model has overfit, if it has become uninterpretable, and if it suffers from data sensitivity.\n",
    "\n",
    "### Probability\n",
    "\n",
    "I wanted to mention that the Decision Tree can return the probability that an observation belongs to a certain class during prediction. I didn't incorporate this into my notebook, but it's possible if you find it useful. The model does this by returning the ratio of training instances for the node the observation falls into.\n",
    "\n",
    "For example, if an ovservation fell into the leaf node in the lower left of the tree trained on the Titanic data, the probability would be $\\frac{\\text{majority class}}{\\text{number of samples}} = \\frac{49}{54} \\approx 0.91$\n",
    "\n",
    "To do this in Scikit Learn, use the `predict_proba` method on the trained tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Understanding the decision tree structure](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#)\n",
    "- [Applied Predictive Modeling](https://www.amazon.com/Applied-Predictive-Modeling-Max-Kuhn-ebook/dp/B00K15TZU0)\n",
    "- [Entry 23: Scoring Classification Models - Theory](https://julielinx.github.io/blog/23_class_score_theory/)\n",
    "- [Entry 24: Scoring Classification Models - Implementation](https://julielinx.github.io/blog/24_class_score_implement/)\n",
    "- [Entry 24 notebook - Scoring Classification Models - Implementation](https://github.com/julielinx/datascience_diaries/blob/master/02_model_eval/24_nb_class_score_implement.ipynb)\n",
    "- [Entry 44]()\n",
    "- [Entry 47]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
