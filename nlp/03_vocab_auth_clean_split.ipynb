{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dec3348-43f1-4b58-b736-ea194a706c76",
   "metadata": {},
   "source": [
    "# Entry NLP3: Clean Data and Split into N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1263b4-9ff7-427d-9297-61198a09397f",
   "metadata": {},
   "source": [
    "In the first entry of this series, I figured out how to process the raw files. In the second entry, I figured out how to load all files in a directory (even if it has subdirectories) and store the data.\n",
    "\n",
    "Now I'm ready to make the analysis case insensitive, remove punctuation and stopwords, and split what's left into n-grams.\n",
    "\n",
    "*Side note:* To be fair, I worked on a pretty extensive NLP problem a few years ago. I'll be reusing code and logic from that project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27823b8c-02bc-4be7-9538-a18e6507f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/julie.fisher/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "import string\n",
    "import re\n",
    "import itertools\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc98c598-c80e-458a-a5a0-d47b7489da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_script(file_path):\n",
    "    corpus = ''\n",
    "    with open(file_path, 'r', encoding='latin-1') as l:\n",
    "        for line in l:\n",
    "            if (re.match('[^\\d+]', line)\n",
    "               ) and (re.match('^(?!\\s*$).+', line)\n",
    "                      ) and not (re.match('(.*www.*)|(.*http:*)', line)\n",
    "                                ) and not (re.match('Sync and correct*', line)):\n",
    "                line = re.sub('</?i>|</?font.*>', '', line)\n",
    "                corpus = corpus + ' ' + line\n",
    "    return corpus\n",
    "\n",
    "def load_files_to_dict(file_path, return_dict):    \n",
    "    for thing in os.scandir(file_path):\n",
    "        if thing.is_dir():\n",
    "            new_path = os.path.join(file_path, thing.name)\n",
    "            new_dict = return_dict[thing.name] = {}\n",
    "            load_files_to_dict(new_path, new_dict)\n",
    "        elif thing.is_file:\n",
    "            return_dict[thing.name] = read_script(f'{file_path}/{thing.name}')\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f44880ad-1a86-4d77-bee7-1adbbcb29532",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), 'data', '1960s')\n",
    "unilayer_dict = load_files_to_dict(file_path, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e98a6f-3002-4b46-b525-cc0362bd53a2",
   "metadata": {},
   "source": [
    "## Remove Punctuation\n",
    "\n",
    "The list of things to remove includes `\\n`, which denotes a newline. I found that including `\\r` (a carriage return) and `\\t` (a tab) is also helpful. These characters can all be hard to spot as they are generally invisible and can randomly attach themselves to otherwise normal words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9ef64-b4f4-442e-86ef-7e140af8d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "newline_list = '\\t\\r\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78366512-4918-49b1-8e9c-2ebccca924e9",
   "metadata": {},
   "source": [
    "Next I'll spell out the special characters I want to remove from the text. Fortunately, there's a list of punctuation included in the `string` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fb6890-4252-4e7e-94b1-b7362739f7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d8070-a493-450f-931d-1de98d69d804",
   "metadata": {},
   "source": [
    "This list is pretty comprehensive. Between this and the `newline_list` I created above all the remaining characters from the \"Remove\" list are now addressed. For quick reference, I still had the following items to remove:\n",
    "\n",
    "- '#'\n",
    "- '-'\n",
    "- '('\n",
    "- ')'\n",
    "- '\"'\n",
    "- '\\n'\n",
    "\n",
    "In my previous project, I discovered the `translate` method. It replaces specified characters with those described in a dictionary or mapping table. The method `maketrans` creates the mapping table. This set of methods is very handy method for proessing strings.\n",
    "\n",
    "Now I can specify all my variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d0091-32c8-4f87-9134-995b0c016d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "newline_list = '\\t\\r\\n'\n",
    "remove_newline = str.maketrans(' ', ' ', newline_list)\n",
    "punct_list = string.punctuation\n",
    "nopunct = str.maketrans('', '', punct_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a011b9db-c6e1-427a-9f8d-7aeb3094d57b",
   "metadata": {},
   "source": [
    "To process the data, I can then just apply `str.translate` to the column holding the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5d1c1-47bb-4765-ab21-c13941352114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[text_col].fillna(\"\").str.lower().str.translate(remove_newline).str.translate(nopunct).str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e6cdb-6143-4d6a-b032-e60753bfec59",
   "metadata": {},
   "source": [
    "This particular strategy hinges on the text being a value in a dataframe column. However, the output from the last notebook is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5793143-a7d8-4e3b-9835-b10670a4a003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Twilight Zone - 3x17 - One More Pallbearer.srt',\n",
       " 'The Twilight Zone - 3x05 - A Game of Pool.srt',\n",
       " 'The Twilight Zone - 2x03 - Nervous Man in a Four Dollar Room.srt',\n",
       " 'The Twilight Zone - 4x05 - Mute.srt',\n",
       " 'The Twilight Zone - 3x04 - The Passersby.srt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unilayer_dict.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8fe5363-7250-4cbf-89be-7b855e2f4253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' You unlock this door\\n with the key of imagination.\\n Beyond it is another dimension-\\n a dimension of sound,\\n a dimension of sight,\\n a dimension of mind.\\n You\\'re moving into a land\\n of both shadow and substance,\\n of things and ideas.\\n You\\'ve just crossed over\\n into the twilight zone.\\n So...\\n \"the undersigned,\\n \"having accepted\\n the following propositions:\\n \"A, that prior\\n to the inception of language,\\n \"man communicated\\n by telepathic means;\\n \"and b, that this ability\\n not only still exists\\n \"but'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unilayer_dict['The Twilight Zone - 4x05 - Mute.srt'][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea832937-fd19-409d-9538-cb180d252cc8",
   "metadata": {},
   "source": [
    "### Convert dictionary to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf9cc03-0d86-4cfc-b4f1-430df8e407d5",
   "metadata": {},
   "source": [
    "A dictionary is easily converted into a dataframe with `pd.DataFrame.from_dict`. The gotsha for this particular use case is the parameter `orient`, it has to be set to `index` in order to use key:value as rows instead of columns. Conversely, it uses the key as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdb58280-4acb-4a4c-9948-a88ea568d132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The Twilight Zone - 3x17 - One More Pallbearer.srt</th>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Twilight Zone - 3x05 - A Game of Pool.srt</th>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Twilight Zone - 2x03 - Nervous Man in a Four Dollar Room.srt</th>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Twilight Zone - 4x05 - Mute.srt</th>\n",
       "      <td>You unlock this door\\n with the key of imagin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Twilight Zone - 3x04 - The Passersby.srt</th>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    0\n",
       "The Twilight Zone - 3x17 - One More Pallbearer.srt   You're traveling\\n through another dimension-...\n",
       "The Twilight Zone - 3x05 - A Game of Pool.srt        You're traveling\\n through another dimension-...\n",
       "The Twilight Zone - 2x03 - Nervous Man in a Fou...   You're traveling\\n through another dimension-...\n",
       "The Twilight Zone - 4x05 - Mute.srt                  You unlock this door\\n with the key of imagin...\n",
       "The Twilight Zone - 3x04 - The Passersby.srt         You're traveling\\n through another dimension-..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(unilayer_dict, orient='index').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a33e1c-366f-4c36-bbab-bf512ddccf6a",
   "metadata": {},
   "source": [
    "The indexing quirk is easily fixed with `reset_index` to make all my variables accessible as columns. However, the I have terrible columns names. Then I give the column names intuitive names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5571175f-f387-41f4-b884-0c1f21f8ea22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Twilight Zone - 3x17 - One More Pallbearer...</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Twilight Zone - 3x05 - A Game of Pool.srt</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Twilight Zone - 2x03 - Nervous Man in a Fo...</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Twilight Zone - 4x05 - Mute.srt</td>\n",
       "      <td>You unlock this door\\n with the key of imagin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Twilight Zone - 3x04 - The Passersby.srt</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               index  \\\n",
       "0  The Twilight Zone - 3x17 - One More Pallbearer...   \n",
       "1      The Twilight Zone - 3x05 - A Game of Pool.srt   \n",
       "2  The Twilight Zone - 2x03 - Nervous Man in a Fo...   \n",
       "3                The Twilight Zone - 4x05 - Mute.srt   \n",
       "4       The Twilight Zone - 3x04 - The Passersby.srt   \n",
       "\n",
       "                                                   0  \n",
       "0   You're traveling\\n through another dimension-...  \n",
       "1   You're traveling\\n through another dimension-...  \n",
       "2   You're traveling\\n through another dimension-...  \n",
       "3   You unlock this door\\n with the key of imagin...  \n",
       "4   You're traveling\\n through another dimension-...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(unilayer_dict, orient='index').reset_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf950a4-57c9-4d24-a7db-c85942e685f8",
   "metadata": {},
   "source": [
    "Ultimately this will all be in a single function or series of functions and the column name won't matter. However, I find it much easier to write and read the code when there are descriptive names - this goes for column names and function names. So I'm going to change the column names to be more easily understood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "497e9914-e3c9-408d-be15-be66d2daed4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_name</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Twilight Zone - 3x17 - One More Pallbearer...</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Twilight Zone - 3x05 - A Game of Pool.srt</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Twilight Zone - 2x03 - Nervous Man in a Fo...</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Twilight Zone - 4x05 - Mute.srt</td>\n",
       "      <td>You unlock this door\\n with the key of imagin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Twilight Zone - 3x04 - The Passersby.srt</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         script_name  \\\n",
       "0  The Twilight Zone - 3x17 - One More Pallbearer...   \n",
       "1      The Twilight Zone - 3x05 - A Game of Pool.srt   \n",
       "2  The Twilight Zone - 2x03 - Nervous Man in a Fo...   \n",
       "3                The Twilight Zone - 4x05 - Mute.srt   \n",
       "4       The Twilight Zone - 3x04 - The Passersby.srt   \n",
       "\n",
       "                                              corpus  \n",
       "0   You're traveling\\n through another dimension-...  \n",
       "1   You're traveling\\n through another dimension-...  \n",
       "2   You're traveling\\n through another dimension-...  \n",
       "3   You unlock this door\\n with the key of imagin...  \n",
       "4   You're traveling\\n through another dimension-...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame.from_dict(unilayer_dict, orient='index').reset_index().rename(columns={'index':'script_name', 0:'corpus'})\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8a94f-9de1-4687-8f56-362a18b8ed17",
   "metadata": {},
   "source": [
    "While it is a single line of code, it is a little unwieldy and I'll need to apply it to all the dictionaries, so I'll write a quick function to do it for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a6352-6c61-4d54-9ec1-3d2a68b6f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_df(script_dict):\n",
    "    return pd.DataFrame.from_dict(script_dict, orient='index').reset_index().rename(columns={'index':'script_name', 0:'corpus'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7654795-c5f0-49de-a2ef-877a3895a5b4",
   "metadata": {},
   "source": [
    "### Remove Punctuation\n",
    "\n",
    "Now that the values are conveniently located in a dataframe, I just have to apply the logic defined earlier. To make it easier, I'll put the logic into a function, then apply that function to the example dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9711bee1-67ef-4bcf-9f7b-4b3610069ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punct_tokens(df, text_col):\n",
    "    newline_list = '\\t\\r\\n'\n",
    "    remove_newline = str.maketrans(' ', ' ', newline_list)\n",
    "    punct_list = string.punctuation\n",
    "    nopunct = str.maketrans('', '', punct_list)\n",
    "    df['no_punct_tokens'] = df[text_col].fillna(\"\").str.lower().str.translate(remove_newline).str.translate(nopunct).str.split()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a074126-cee3-45a8-930f-8ad8bd030bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_name</th>\n",
       "      <th>corpus</th>\n",
       "      <th>no_punct_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Twilight Zone - 3x17 - One More Pallbearer...</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Twilight Zone - 3x05 - A Game of Pool.srt</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Twilight Zone - 2x03 - Nervous Man in a Fo...</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Twilight Zone - 4x05 - Mute.srt</td>\n",
       "      <td>You unlock this door\\n with the key of imagin...</td>\n",
       "      <td>[you, unlock, this, door, with, the, key, of, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Twilight Zone - 3x04 - The Passersby.srt</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         script_name  \\\n",
       "0  The Twilight Zone - 3x17 - One More Pallbearer...   \n",
       "1      The Twilight Zone - 3x05 - A Game of Pool.srt   \n",
       "2  The Twilight Zone - 2x03 - Nervous Man in a Fo...   \n",
       "3                The Twilight Zone - 4x05 - Mute.srt   \n",
       "4       The Twilight Zone - 3x04 - The Passersby.srt   \n",
       "\n",
       "                                              corpus  \\\n",
       "0   You're traveling\\n through another dimension-...   \n",
       "1   You're traveling\\n through another dimension-...   \n",
       "2   You're traveling\\n through another dimension-...   \n",
       "3   You unlock this door\\n with the key of imagin...   \n",
       "4   You're traveling\\n through another dimension-...   \n",
       "\n",
       "                                     no_punct_tokens  \n",
       "0  [youre, traveling, through, another, dimension...  \n",
       "1  [youre, traveling, through, another, dimension...  \n",
       "2  [youre, traveling, through, another, dimension...  \n",
       "3  [you, unlock, this, door, with, the, key, of, ...  \n",
       "4  [youre, traveling, through, another, dimension...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_test = punct_tokens(test, 'corpus')\n",
    "punct_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f1884-ec9e-4bab-b400-b0da3bcb3c3f",
   "metadata": {},
   "source": [
    "## Remove stopwords\n",
    "\n",
    "Now that the punctuation is out of the way, I can start thinking about the breaking the text into different sized n-grams. What has worked for me in the past is to split the string that's had punctuation removed into unigrams (called one-grams in the homework), the create different sizes of n-gram from there.\n",
    "\n",
    "However, to get words with actual meaning, I first need to remove stopwords.\n",
    "\n",
    "The `nltk` library has a handy list of stopwords. *Note:* Using the `nltk` library is beyond the scope of this series of entries. Historically, my use of the `nltk` libray has mostly been limited to the stopword list and n-gram creation. I have used the `FreqDist` and `ConditionalFreqDist` functions, but found them a bit tempermental and ended up coding frequency counts myself for this exercise (see the next post)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a0458f4-d388-48be-af17-fa2740a28b0c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba1046-6056-4de4-b0e7-fcda80936fcb",
   "metadata": {},
   "source": [
    "The best way I found to remove stopwords was to use list comprehension in a lambda function.\n",
    "\n",
    "All the code for this section was re-used, so I'll lump the results all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "263ca823-c3da-43f7-a30b-212de9eed576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngrams(df):\n",
    "    stop = nltk.corpus.stopwords.words('english')\n",
    "    df['unigrams'] = df['no_punct_tokens'].apply(lambda x: [item for item in x if item not in stop])\n",
    "    df['bigrams'] = df['unigrams'].apply(lambda x:(list(nltk.bigrams(x))))\n",
    "    df['trigrams'] = df['unigrams'].apply(lambda x:(list(nltk.trigrams(x))))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "884d1974-ac8b-439d-904f-391d539e3ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_name</th>\n",
       "      <th>corpus</th>\n",
       "      <th>no_punct_tokens</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Twilight Zone - 3x17 - One More Pallbearer...</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "      <td>[youre, traveling, another, dimension, dimensi...</td>\n",
       "      <td>[(youre, traveling), (traveling, another), (an...</td>\n",
       "      <td>[(youre, traveling, another), (traveling, anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Twilight Zone - 3x05 - A Game of Pool.srt</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "      <td>[youre, traveling, another, dimension, dimensi...</td>\n",
       "      <td>[(youre, traveling), (traveling, another), (an...</td>\n",
       "      <td>[(youre, traveling, another), (traveling, anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Twilight Zone - 2x03 - Nervous Man in a Fo...</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "      <td>[youre, traveling, another, dimension, dimensi...</td>\n",
       "      <td>[(youre, traveling), (traveling, another), (an...</td>\n",
       "      <td>[(youre, traveling, another), (traveling, anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Twilight Zone - 4x05 - Mute.srt</td>\n",
       "      <td>You unlock this door\\n with the key of imagin...</td>\n",
       "      <td>[you, unlock, this, door, with, the, key, of, ...</td>\n",
       "      <td>[unlock, door, key, imagination, beyond, anoth...</td>\n",
       "      <td>[(unlock, door), (door, key), (key, imaginatio...</td>\n",
       "      <td>[(unlock, door, key), (door, key, imagination)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Twilight Zone - 3x04 - The Passersby.srt</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "      <td>[youre, traveling, another, dimension, dimensi...</td>\n",
       "      <td>[(youre, traveling), (traveling, another), (an...</td>\n",
       "      <td>[(youre, traveling, another), (traveling, anot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         script_name  \\\n",
       "0  The Twilight Zone - 3x17 - One More Pallbearer...   \n",
       "1      The Twilight Zone - 3x05 - A Game of Pool.srt   \n",
       "2  The Twilight Zone - 2x03 - Nervous Man in a Fo...   \n",
       "3                The Twilight Zone - 4x05 - Mute.srt   \n",
       "4       The Twilight Zone - 3x04 - The Passersby.srt   \n",
       "\n",
       "                                              corpus  \\\n",
       "0   You're traveling\\n through another dimension-...   \n",
       "1   You're traveling\\n through another dimension-...   \n",
       "2   You're traveling\\n through another dimension-...   \n",
       "3   You unlock this door\\n with the key of imagin...   \n",
       "4   You're traveling\\n through another dimension-...   \n",
       "\n",
       "                                     no_punct_tokens  \\\n",
       "0  [youre, traveling, through, another, dimension...   \n",
       "1  [youre, traveling, through, another, dimension...   \n",
       "2  [youre, traveling, through, another, dimension...   \n",
       "3  [you, unlock, this, door, with, the, key, of, ...   \n",
       "4  [youre, traveling, through, another, dimension...   \n",
       "\n",
       "                                            unigrams  \\\n",
       "0  [youre, traveling, another, dimension, dimensi...   \n",
       "1  [youre, traveling, another, dimension, dimensi...   \n",
       "2  [youre, traveling, another, dimension, dimensi...   \n",
       "3  [unlock, door, key, imagination, beyond, anoth...   \n",
       "4  [youre, traveling, another, dimension, dimensi...   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(youre, traveling), (traveling, another), (an...   \n",
       "1  [(youre, traveling), (traveling, another), (an...   \n",
       "2  [(youre, traveling), (traveling, another), (an...   \n",
       "3  [(unlock, door), (door, key), (key, imaginatio...   \n",
       "4  [(youre, traveling), (traveling, another), (an...   \n",
       "\n",
       "                                            trigrams  \n",
       "0  [(youre, traveling, another), (traveling, anot...  \n",
       "1  [(youre, traveling, another), (traveling, anot...  \n",
       "2  [(youre, traveling, another), (traveling, anot...  \n",
       "3  [(unlock, door, key), (door, key, imagination)...  \n",
       "4  [(youre, traveling, another), (traveling, anot...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_ngrams(punct_test).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba9c0f-f29f-48af-95f1-f51f0aab47b2",
   "metadata": {},
   "source": [
    "I appreciate this data structure because if there is anything that doesn't make sense later in the analysis, I can search for it and track it back to the source, i.e. as long as I can find it in the designated n-gram column, I can see what the corpus looked like in the original form (the full concatenated string), after removal of punctuation, after removal of the stopwords, and converted to n-grams as well as being able to track it back to the script it came from because I have the script name.\n",
    "\n",
    "The code to create this dataframe is a good chunk of code that's all related, so I'll combine it into a single function for easy of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c93ccd-755e-4d1f-9c16-67fbd6b215fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_df(script_dict, text_col):\n",
    "    df = convert_dict_df(script_dict)\n",
    "    df = punct_tokens(df, text_col)\n",
    "    df = create_ngrams(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f093714-aec4-485c-bd20-06c53af0fdac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_name</th>\n",
       "      <th>corpus</th>\n",
       "      <th>no_punct_tokens</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Twilight Zone - 3x17 - One More Pallbearer...</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "      <td>[youre, traveling, another, dimension, dimensi...</td>\n",
       "      <td>[(youre, traveling), (traveling, another), (an...</td>\n",
       "      <td>[(youre, traveling, another), (traveling, anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Twilight Zone - 3x05 - A Game of Pool.srt</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "      <td>[youre, traveling, another, dimension, dimensi...</td>\n",
       "      <td>[(youre, traveling), (traveling, another), (an...</td>\n",
       "      <td>[(youre, traveling, another), (traveling, anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Twilight Zone - 2x03 - Nervous Man in a Fo...</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "      <td>[youre, traveling, another, dimension, dimensi...</td>\n",
       "      <td>[(youre, traveling), (traveling, another), (an...</td>\n",
       "      <td>[(youre, traveling, another), (traveling, anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Twilight Zone - 4x05 - Mute.srt</td>\n",
       "      <td>You unlock this door\\n with the key of imagin...</td>\n",
       "      <td>[you, unlock, this, door, with, the, key, of, ...</td>\n",
       "      <td>[unlock, door, key, imagination, beyond, anoth...</td>\n",
       "      <td>[(unlock, door), (door, key), (key, imaginatio...</td>\n",
       "      <td>[(unlock, door, key), (door, key, imagination)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Twilight Zone - 3x04 - The Passersby.srt</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "      <td>[youre, traveling, another, dimension, dimensi...</td>\n",
       "      <td>[(youre, traveling), (traveling, another), (an...</td>\n",
       "      <td>[(youre, traveling, another), (traveling, anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>The Twilight Zone - s05e36 - The Bewitchin' Po...</td>\n",
       "      <td>You unlock this door\\n with the key of imagin...</td>\n",
       "      <td>[you, unlock, this, door, with, the, key, of, ...</td>\n",
       "      <td>[unlock, door, key, imagination, beyond, anoth...</td>\n",
       "      <td>[(unlock, door), (door, key), (key, imaginatio...</td>\n",
       "      <td>[(unlock, door, key), (door, key, imagination)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>The Twilight Zone - 3x03 - The Shelter.srt</td>\n",
       "      <td>You're traveling\\n through another dimension-...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "      <td>[youre, traveling, another, dimension, dimensi...</td>\n",
       "      <td>[(youre, traveling), (traveling, another), (an...</td>\n",
       "      <td>[(youre, traveling, another), (traveling, anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>The Twilight Zone - s05e21 - Spur of the Momen...</td>\n",
       "      <td>You unlock this door\\n with the key of imagin...</td>\n",
       "      <td>[you, unlock, this, door, with, the, key, of, ...</td>\n",
       "      <td>[unlock, door, key, imagination, beyond, anoth...</td>\n",
       "      <td>[(unlock, door), (door, key), (key, imaginatio...</td>\n",
       "      <td>[(unlock, door, key), (door, key, imagination)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>The Twilight Zone - 2x29 - The Obsolete Man.srt</td>\n",
       "      <td>You're traveling\\n through another dimension\\...</td>\n",
       "      <td>[youre, traveling, through, another, dimension...</td>\n",
       "      <td>[youre, traveling, another, dimension, dimensi...</td>\n",
       "      <td>[(youre, traveling), (traveling, another), (an...</td>\n",
       "      <td>[(youre, traveling, another), (traveling, anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>The Twilight Zone - s05e13 - Ring-A-Ding Girl.srt</td>\n",
       "      <td>You unlock this door\\n with the key of imagin...</td>\n",
       "      <td>[you, unlock, this, door, with, the, key, of, ...</td>\n",
       "      <td>[unlock, door, key, imagination, beyond, anoth...</td>\n",
       "      <td>[(unlock, door), (door, key), (key, imaginatio...</td>\n",
       "      <td>[(unlock, door, key), (door, key, imagination)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           script_name  \\\n",
       "0    The Twilight Zone - 3x17 - One More Pallbearer...   \n",
       "1        The Twilight Zone - 3x05 - A Game of Pool.srt   \n",
       "2    The Twilight Zone - 2x03 - Nervous Man in a Fo...   \n",
       "3                  The Twilight Zone - 4x05 - Mute.srt   \n",
       "4         The Twilight Zone - 3x04 - The Passersby.srt   \n",
       "..                                                 ...   \n",
       "116  The Twilight Zone - s05e36 - The Bewitchin' Po...   \n",
       "117         The Twilight Zone - 3x03 - The Shelter.srt   \n",
       "118  The Twilight Zone - s05e21 - Spur of the Momen...   \n",
       "119    The Twilight Zone - 2x29 - The Obsolete Man.srt   \n",
       "120  The Twilight Zone - s05e13 - Ring-A-Ding Girl.srt   \n",
       "\n",
       "                                                corpus  \\\n",
       "0     You're traveling\\n through another dimension-...   \n",
       "1     You're traveling\\n through another dimension-...   \n",
       "2     You're traveling\\n through another dimension-...   \n",
       "3     You unlock this door\\n with the key of imagin...   \n",
       "4     You're traveling\\n through another dimension-...   \n",
       "..                                                 ...   \n",
       "116   You unlock this door\\n with the key of imagin...   \n",
       "117   You're traveling\\n through another dimension-...   \n",
       "118   You unlock this door\\n with the key of imagin...   \n",
       "119   You're traveling\\n through another dimension\\...   \n",
       "120   You unlock this door\\n with the key of imagin...   \n",
       "\n",
       "                                       no_punct_tokens  \\\n",
       "0    [youre, traveling, through, another, dimension...   \n",
       "1    [youre, traveling, through, another, dimension...   \n",
       "2    [youre, traveling, through, another, dimension...   \n",
       "3    [you, unlock, this, door, with, the, key, of, ...   \n",
       "4    [youre, traveling, through, another, dimension...   \n",
       "..                                                 ...   \n",
       "116  [you, unlock, this, door, with, the, key, of, ...   \n",
       "117  [youre, traveling, through, another, dimension...   \n",
       "118  [you, unlock, this, door, with, the, key, of, ...   \n",
       "119  [youre, traveling, through, another, dimension...   \n",
       "120  [you, unlock, this, door, with, the, key, of, ...   \n",
       "\n",
       "                                              unigrams  \\\n",
       "0    [youre, traveling, another, dimension, dimensi...   \n",
       "1    [youre, traveling, another, dimension, dimensi...   \n",
       "2    [youre, traveling, another, dimension, dimensi...   \n",
       "3    [unlock, door, key, imagination, beyond, anoth...   \n",
       "4    [youre, traveling, another, dimension, dimensi...   \n",
       "..                                                 ...   \n",
       "116  [unlock, door, key, imagination, beyond, anoth...   \n",
       "117  [youre, traveling, another, dimension, dimensi...   \n",
       "118  [unlock, door, key, imagination, beyond, anoth...   \n",
       "119  [youre, traveling, another, dimension, dimensi...   \n",
       "120  [unlock, door, key, imagination, beyond, anoth...   \n",
       "\n",
       "                                               bigrams  \\\n",
       "0    [(youre, traveling), (traveling, another), (an...   \n",
       "1    [(youre, traveling), (traveling, another), (an...   \n",
       "2    [(youre, traveling), (traveling, another), (an...   \n",
       "3    [(unlock, door), (door, key), (key, imaginatio...   \n",
       "4    [(youre, traveling), (traveling, another), (an...   \n",
       "..                                                 ...   \n",
       "116  [(unlock, door), (door, key), (key, imaginatio...   \n",
       "117  [(youre, traveling), (traveling, another), (an...   \n",
       "118  [(unlock, door), (door, key), (key, imaginatio...   \n",
       "119  [(youre, traveling), (traveling, another), (an...   \n",
       "120  [(unlock, door), (door, key), (key, imaginatio...   \n",
       "\n",
       "                                              trigrams  \n",
       "0    [(youre, traveling, another), (traveling, anot...  \n",
       "1    [(youre, traveling, another), (traveling, anot...  \n",
       "2    [(youre, traveling, another), (traveling, anot...  \n",
       "3    [(unlock, door, key), (door, key, imagination)...  \n",
       "4    [(youre, traveling, another), (traveling, anot...  \n",
       "..                                                 ...  \n",
       "116  [(unlock, door, key), (door, key, imagination)...  \n",
       "117  [(youre, traveling, another), (traveling, anot...  \n",
       "118  [(unlock, door, key), (door, key, imagination)...  \n",
       "119  [(youre, traveling, another), (traveling, anot...  \n",
       "120  [(unlock, door, key), (door, key, imagination)...  \n",
       "\n",
       "[121 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authentic_ngram_df = create_ngram_df(unilayer_dict, 'corpus')\n",
    "authentic_ngram_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6315b4f-ad9d-4dad-907c-b9708429d527",
   "metadata": {},
   "source": [
    "To handle the multiple corpora of the 21st century scripts, I retained the dictionary-holding-another-data-structure set up. The name of each grouping ('Pan-Am', 'Mad_Med', 'The_Kennedys', 'X-Men_First_Class') is a key and the dataframe is the value. Using this, I can continue to reap the benefits of my functions, while keeping the groups, and their individual analyses, separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "888fda0e-4901-4101-ba82-e7720a479229",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ngram_dict = {}\n",
    "for script_group in list(bilayer_dict.keys()):\n",
    "    test_ngram_dict[script_group] = create_ngram_df(bilayer_dict[script_group], 'corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66bafde2-980d-4ddd-829c-a4e20b6058a6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_name</th>\n",
       "      <th>corpus</th>\n",
       "      <th>no_punct_tokens</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pan.Am.S01E09.srt</td>\n",
       "      <td>Previously on \"Pan Am\"...\\n Look, I get to se...</td>\n",
       "      <td>[previously, on, pan, am, look, i, get, to, se...</td>\n",
       "      <td>[previously, pan, look, get, see, world, sam, ...</td>\n",
       "      <td>[(previously, pan), (pan, look), (look, get), ...</td>\n",
       "      <td>[(previously, pan, look), (pan, look, get), (l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pan.Am.S01E08.srt</td>\n",
       "      <td>ï»¿1\\n Previously on \"Pan Am\"...\\n Let's keep...</td>\n",
       "      <td>[ï»¿1, previously, on, pan, am, lets, keep, it...</td>\n",
       "      <td>[ï»¿1, previously, pan, lets, keep, new, york,...</td>\n",
       "      <td>[(ï»¿1, previously), (previously, pan), (pan, ...</td>\n",
       "      <td>[(ï»¿1, previously, pan), (previously, pan, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pan.Am.S01E05.srt</td>\n",
       "      <td>Previously on \"Pan Am\"...\\n What do you think...</td>\n",
       "      <td>[previously, on, pan, am, what, do, you, think...</td>\n",
       "      <td>[previously, pan, think, youre, ran, away, wed...</td>\n",
       "      <td>[(previously, pan), (pan, think), (think, your...</td>\n",
       "      <td>[(previously, pan, think), (pan, think, youre)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pan.Am.S01E11.srt</td>\n",
       "      <td>Previously on \"Pan Am\".\\n MI6 will want answe...</td>\n",
       "      <td>[previously, on, pan, am, mi6, will, want, ans...</td>\n",
       "      <td>[previously, pan, mi6, want, answers, take, li...</td>\n",
       "      <td>[(previously, pan), (pan, mi6), (mi6, want), (...</td>\n",
       "      <td>[(previously, pan, mi6), (pan, mi6, want), (mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pan.Am.S01E10.srt</td>\n",
       "      <td>Previously on \"Pan Am\"...\\n I bet you've got ...</td>\n",
       "      <td>[previously, on, pan, am, i, bet, youve, got, ...</td>\n",
       "      <td>[previously, pan, bet, youve, got, surprises, ...</td>\n",
       "      <td>[(previously, pan), (pan, bet), (bet, youve), ...</td>\n",
       "      <td>[(previously, pan, bet), (pan, bet, youve), (b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pan.Am.S01E04.srt</td>\n",
       "      <td>Previously on \"Pan Am\"...\\n - You're gonna me...</td>\n",
       "      <td>[previously, on, pan, am, youre, gonna, meet, ...</td>\n",
       "      <td>[previously, pan, youre, gonna, meet, kennedy,...</td>\n",
       "      <td>[(previously, pan), (pan, youre), (youre, gonn...</td>\n",
       "      <td>[(previously, pan, youre), (pan, youre, gonna)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pan.Am.S01E12.srt</td>\n",
       "      <td>Previously on \"Pan Am\".\\n We'd like to move y...</td>\n",
       "      <td>[previously, on, pan, am, wed, like, to, move,...</td>\n",
       "      <td>[previously, pan, wed, like, move, courier, ag...</td>\n",
       "      <td>[(previously, pan), (pan, wed), (wed, like), (...</td>\n",
       "      <td>[(previously, pan, wed), (pan, wed, like), (we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pan.Am.S01E06.srt</td>\n",
       "      <td>Previously on \"Pan Am\".\\n Why don't you came ...</td>\n",
       "      <td>[previously, on, pan, am, why, dont, you, came...</td>\n",
       "      <td>[previously, pan, dont, came, fog, captain, af...</td>\n",
       "      <td>[(previously, pan), (pan, dont), (dont, came),...</td>\n",
       "      <td>[(previously, pan, dont), (pan, dont, came), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pan.Am.S01E07.srt</td>\n",
       "      <td>Previously on \"Pan Am\"...\\n You smell like wh...</td>\n",
       "      <td>[previously, on, pan, am, you, smell, like, wh...</td>\n",
       "      <td>[previously, pan, smell, like, whiskey, cigare...</td>\n",
       "      <td>[(previously, pan), (pan, smell), (smell, like...</td>\n",
       "      <td>[(previously, pan, smell), (pan, smell, like),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pan.Am.S01E13.srt</td>\n",
       "      <td>Previously on \"Pan Am\"...\\n Let's keep it in ...</td>\n",
       "      <td>[previously, on, pan, am, lets, keep, it, in, ...</td>\n",
       "      <td>[previously, pan, lets, keep, new, york, ginny...</td>\n",
       "      <td>[(previously, pan), (pan, lets), (lets, keep),...</td>\n",
       "      <td>[(previously, pan, lets), (pan, lets, keep), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pan.Am.S01E03.srt</td>\n",
       "      <td>Previously on \"Pan Am\".\\n You're always disap...</td>\n",
       "      <td>[previously, on, pan, am, youre, always, disap...</td>\n",
       "      <td>[previously, pan, youre, always, disappearing,...</td>\n",
       "      <td>[(previously, pan), (pan, youre), (youre, alwa...</td>\n",
       "      <td>[(previously, pan, youre), (pan, youre, always...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pan.Am.S01E02.srt</td>\n",
       "      <td>Previously on \"Pan Am\"...\\n Do you not wanna ...</td>\n",
       "      <td>[previously, on, pan, am, do, you, not, wanna,...</td>\n",
       "      <td>[previously, pan, wanna, get, married, need, d...</td>\n",
       "      <td>[(previously, pan), (pan, wanna), (wanna, get)...</td>\n",
       "      <td>[(previously, pan, wanna), (pan, wanna, get), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pan.Am.S01E14.srt</td>\n",
       "      <td>Previously on \"Pan Am\"...\\n There's a dealer ...</td>\n",
       "      <td>[previously, on, pan, am, theres, a, dealer, i...</td>\n",
       "      <td>[previously, pan, theres, dealer, london, whos...</td>\n",
       "      <td>[(previously, pan), (pan, theres), (theres, de...</td>\n",
       "      <td>[(previously, pan, theres), (pan, theres, deal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pan.Am.S01E01.srt</td>\n",
       "      <td>ï»¿1\\n There you are.\\n Enjoy your flight.\\n ...</td>\n",
       "      <td>[ï»¿1, there, you, are, enjoy, your, flight, j...</td>\n",
       "      <td>[ï»¿1, enjoy, flight, jet, clipper, service, u...</td>\n",
       "      <td>[(ï»¿1, enjoy), (enjoy, flight), (flight, jet)...</td>\n",
       "      <td>[(ï»¿1, enjoy, flight), (enjoy, flight, jet), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          script_name                                             corpus  \\\n",
       "0   Pan.Am.S01E09.srt   Previously on \"Pan Am\"...\\n Look, I get to se...   \n",
       "1   Pan.Am.S01E08.srt   ï»¿1\\n Previously on \"Pan Am\"...\\n Let's keep...   \n",
       "2   Pan.Am.S01E05.srt   Previously on \"Pan Am\"...\\n What do you think...   \n",
       "3   Pan.Am.S01E11.srt   Previously on \"Pan Am\".\\n MI6 will want answe...   \n",
       "4   Pan.Am.S01E10.srt   Previously on \"Pan Am\"...\\n I bet you've got ...   \n",
       "5   Pan.Am.S01E04.srt   Previously on \"Pan Am\"...\\n - You're gonna me...   \n",
       "6   Pan.Am.S01E12.srt   Previously on \"Pan Am\".\\n We'd like to move y...   \n",
       "7   Pan.Am.S01E06.srt   Previously on \"Pan Am\".\\n Why don't you came ...   \n",
       "8   Pan.Am.S01E07.srt   Previously on \"Pan Am\"...\\n You smell like wh...   \n",
       "9   Pan.Am.S01E13.srt   Previously on \"Pan Am\"...\\n Let's keep it in ...   \n",
       "10  Pan.Am.S01E03.srt   Previously on \"Pan Am\".\\n You're always disap...   \n",
       "11  Pan.Am.S01E02.srt   Previously on \"Pan Am\"...\\n Do you not wanna ...   \n",
       "12  Pan.Am.S01E14.srt   Previously on \"Pan Am\"...\\n There's a dealer ...   \n",
       "13  Pan.Am.S01E01.srt   ï»¿1\\n There you are.\\n Enjoy your flight.\\n ...   \n",
       "\n",
       "                                      no_punct_tokens  \\\n",
       "0   [previously, on, pan, am, look, i, get, to, se...   \n",
       "1   [ï»¿1, previously, on, pan, am, lets, keep, it...   \n",
       "2   [previously, on, pan, am, what, do, you, think...   \n",
       "3   [previously, on, pan, am, mi6, will, want, ans...   \n",
       "4   [previously, on, pan, am, i, bet, youve, got, ...   \n",
       "5   [previously, on, pan, am, youre, gonna, meet, ...   \n",
       "6   [previously, on, pan, am, wed, like, to, move,...   \n",
       "7   [previously, on, pan, am, why, dont, you, came...   \n",
       "8   [previously, on, pan, am, you, smell, like, wh...   \n",
       "9   [previously, on, pan, am, lets, keep, it, in, ...   \n",
       "10  [previously, on, pan, am, youre, always, disap...   \n",
       "11  [previously, on, pan, am, do, you, not, wanna,...   \n",
       "12  [previously, on, pan, am, theres, a, dealer, i...   \n",
       "13  [ï»¿1, there, you, are, enjoy, your, flight, j...   \n",
       "\n",
       "                                             unigrams  \\\n",
       "0   [previously, pan, look, get, see, world, sam, ...   \n",
       "1   [ï»¿1, previously, pan, lets, keep, new, york,...   \n",
       "2   [previously, pan, think, youre, ran, away, wed...   \n",
       "3   [previously, pan, mi6, want, answers, take, li...   \n",
       "4   [previously, pan, bet, youve, got, surprises, ...   \n",
       "5   [previously, pan, youre, gonna, meet, kennedy,...   \n",
       "6   [previously, pan, wed, like, move, courier, ag...   \n",
       "7   [previously, pan, dont, came, fog, captain, af...   \n",
       "8   [previously, pan, smell, like, whiskey, cigare...   \n",
       "9   [previously, pan, lets, keep, new, york, ginny...   \n",
       "10  [previously, pan, youre, always, disappearing,...   \n",
       "11  [previously, pan, wanna, get, married, need, d...   \n",
       "12  [previously, pan, theres, dealer, london, whos...   \n",
       "13  [ï»¿1, enjoy, flight, jet, clipper, service, u...   \n",
       "\n",
       "                                              bigrams  \\\n",
       "0   [(previously, pan), (pan, look), (look, get), ...   \n",
       "1   [(ï»¿1, previously), (previously, pan), (pan, ...   \n",
       "2   [(previously, pan), (pan, think), (think, your...   \n",
       "3   [(previously, pan), (pan, mi6), (mi6, want), (...   \n",
       "4   [(previously, pan), (pan, bet), (bet, youve), ...   \n",
       "5   [(previously, pan), (pan, youre), (youre, gonn...   \n",
       "6   [(previously, pan), (pan, wed), (wed, like), (...   \n",
       "7   [(previously, pan), (pan, dont), (dont, came),...   \n",
       "8   [(previously, pan), (pan, smell), (smell, like...   \n",
       "9   [(previously, pan), (pan, lets), (lets, keep),...   \n",
       "10  [(previously, pan), (pan, youre), (youre, alwa...   \n",
       "11  [(previously, pan), (pan, wanna), (wanna, get)...   \n",
       "12  [(previously, pan), (pan, theres), (theres, de...   \n",
       "13  [(ï»¿1, enjoy), (enjoy, flight), (flight, jet)...   \n",
       "\n",
       "                                             trigrams  \n",
       "0   [(previously, pan, look), (pan, look, get), (l...  \n",
       "1   [(ï»¿1, previously, pan), (previously, pan, le...  \n",
       "2   [(previously, pan, think), (pan, think, youre)...  \n",
       "3   [(previously, pan, mi6), (pan, mi6, want), (mi...  \n",
       "4   [(previously, pan, bet), (pan, bet, youve), (b...  \n",
       "5   [(previously, pan, youre), (pan, youre, gonna)...  \n",
       "6   [(previously, pan, wed), (pan, wed, like), (we...  \n",
       "7   [(previously, pan, dont), (pan, dont, came), (...  \n",
       "8   [(previously, pan, smell), (pan, smell, like),...  \n",
       "9   [(previously, pan, lets), (pan, lets, keep), (...  \n",
       "10  [(previously, pan, youre), (pan, youre, always...  \n",
       "11  [(previously, pan, wanna), (pan, wanna, get), ...  \n",
       "12  [(previously, pan, theres), (pan, theres, deal...  \n",
       "13  [(ï»¿1, enjoy, flight), (enjoy, flight, jet), ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ngram_dict['Pan_Am']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ec44a9-33d0-42d9-bf98-a833370f071b",
   "metadata": {},
   "source": [
    "Putting it all together, the functions look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2153eb9-ab82-42a0-96d1-2599c942a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_df(script_dict):\n",
    "    return pd.DataFrame.from_dict(script_dict, orient='index').reset_index().rename(columns={'index':'script_name', 0:'corpus'})\n",
    "\n",
    "def punct_tokens(df, text_col):\n",
    "    newline_list = '\\t\\r\\n'\n",
    "    remove_newline = str.maketrans(' ', ' ', newline_list)\n",
    "    punct_list = string.punctuation\n",
    "    nopunct = str.maketrans('', '', punct_list)\n",
    "    df['no_punct_tokens'] = df[text_col].fillna(\"\").str.lower().str.translate(remove_newline).str.translate(nopunct).str.split()\n",
    "    return df\n",
    "\n",
    "def create_ngrams(df):\n",
    "    stop = nltk.corpus.stopwords.words('english')\n",
    "    df['unigrams'] = df['no_punct_tokens'].apply(lambda x: [item for item in x if item not in stop])\n",
    "    df['bigrams'] = df['unigrams'].apply(lambda x:(list(nltk.bigrams(x))))\n",
    "    df['trigrams'] = df['unigrams'].apply(lambda x:(list(nltk.trigrams(x))))\n",
    "    return df\n",
    "\n",
    "def create_ngram_df(script_dict, text_col):\n",
    "    df = convert_dict_df(script_dict)\n",
    "    df = punct_tokens(df, text_col)\n",
    "    df = create_ngrams(df)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
