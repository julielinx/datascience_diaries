{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entry 10 - Reorder Pre-processing and Make Predictions\n",
    "\n",
    "Using the pre-processing determined in entries 6-8, predict mass while only changing the surface pressure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "<font color='red'>Entry 9</font> resulted in a trained model. However, I ran into several problems that need to be addressed before a prediction can be made. These problems are:\n",
    "\n",
    "- Categorical and scaling parameters weren't retained, so they couldn't be applied to the test data\n",
    "- Target value would scaled using standardization, rendering the predictions uninterpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Options\n",
    "\n",
    "Retaining the pre-processing transformations is the easy one as there's basically one option: retain the information so you can apply the same transformations later. This is easily accomplished with the preprocessing module of Scikit Learn. The information just has to be returned as part of the function.\n",
    "\n",
    "Addressing the second point requires more thought. The target value being scaled is making me reconsider the order in which the pre-processing occurs. I could just separate the target value and features at the scaling step, but I think I should address several other concerns at this point so the process to date is easier to transfer to other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Proposed Solution\n",
    "\n",
    "Based on the issues encountered, I propose updating my pre-processing process to the following steps:\n",
    "\n",
    "### Split dataset\n",
    "\n",
    "The very first step in the standardized process after loading the data should be to split it into train, test, and reserve datasets.\n",
    "\n",
    "- **Train**: where pre-processing is run, features are generated, and the model is trained\n",
    "- **Test**: where the trained model(s) is/are tested on data never seen before and hyperparameters are evaluated\n",
    "- **Reserve**: where the final model is assessed\n",
    "\n",
    "### Separate target value and features\n",
    "\n",
    "The target value doesn't need to be pre-processed (except maybe for missing values, but as I'm only dealing with supervised learning at this stage, there shouldn't be any missing values in the target). The easiest way to ensure this is to split off the target from the rest of the data.\n",
    "\n",
    "### Determine collinearity\n",
    "\n",
    "Correlation doesn't care about scaling (I checked - the values I got when running correlation on the unscaled features matched the values Sabber and I got when running it on standardized values). To speed up pre-processing, I'm going to remove collinear features before applying transformations.\n",
    "\n",
    "Correlation only works on numeric values. I'm going to explore determining collinearity of categorical-categorical and categorical-numeric features in a <font color='red'>future entry</font>. For now, I'm going to run collinearity on just the numeric features (due to the transformation issues listed in the 'Apply transformations' section).\n",
    "\n",
    "### Apply transformations\n",
    "\n",
    "This is where I encode categorical features and scale numeric features. To ensure the categorical features don't accidentally get scaled (which they did in notebook entry 8 and 9), scaling should happen first on just numeric features, then categorical features can be encoded. Per [these](https://stats.stackexchange.com/questions/169350/centering-and-scaling-dummy-variables) two [posts](https://en.wikipedia.org/wiki/Categorical_variable), categorical features (including 1/0 encoding) should never be scaled.\n",
    "\n",
    "When scaling the numeric features, one of the books/tutorials/blogs recommended scaling when the values were different by an order of magnitude (power of 10). In <font color='red'>Entry 8</font> I delved into centering and scaling. The two most common options in scaling are normalization (centering and dividing by range) and standardization (centering and dividing by standard deviation). Normalization brings the mean to 0 and the range of values between 0 and 1. Standardization brings the mean to 0 and the standard deviation to 1. There is no set range on the standardized value, but because of [the way standard deviation works](https://en.wikipedia.org/wiki/Standard_deviation#Rules_for_normally_distributed_data), for normally distributed data 68.3% of values should be within 1 standard deviation, 95.4% within 2 standard deviations, and 99.7% within 3 standard deviations. As such, values an order of magnitude larger between features should be rare.\n",
    "\n",
    "If there are more than 100 categories in a categorical feature, that could present a problem. However, I plan to delve further into categorical features and the options for encoding then in a <font color='red'>future entry</font>.\n",
    "\n",
    "### Make predictions\n",
    "\n",
    "Once the above steps have been implemented in order, I can then make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fail\n",
    "\n",
    "### The predictions\n",
    "\n",
    "I used the pipeline to predict both mass and atmospheric mass where I only varied the surface pressure in the 'test' data. At first glance, the results don't make any sense - both sets of predictions returned negative values. In attempting to raise the surface pressure of Mars I expected positive values for both predicted mass and atmospheric mass. Upon further reflection, I was able to make sense of the mass prediction.\n",
    "\n",
    "Changes in mass effect many of the other variables, such as diameter, gravity, density, escape velocity, etc via known mathematical equations (see <font color='red'>Entry 7</font> for the escape velocity equation). By leaving these values all the same and only changing surface pressure there would need to be more atmosphere per surface area. As atmospheric mass was removed from the features by collinearity, I expected the mass to go up. However, escape velocity and density stayed the same, putting a constraint on mass. A decrease in mass (and thus diameter - also removed by collinearity) would then allow more atmosphere per surface area.\n",
    "\n",
    "This finding supports the addage '[garbage in garbage out](https://en.wikipedia.org/wiki/Garbage_in,_garbage_out).' I totally earned this unusable result by being lazy in changing only one value and making up my own test data. A better way to solve this particular problem would be to enter the mathematical equations so that when you change one value, the others will update accordingly.\n",
    "\n",
    "### Time\n",
    "\n",
    "The amount of time dedicted to these changes was also a complete failure from the 1-2 hour goal. There were quite a few major revisions for this entry, which maybe should have been split out to be addressed individually. However, this entry resulted in a working pipeline to go from loading data to making a prediction. Some additional automation will need to be completed around splitting the train/test data, creating the model/making predictions, and addressing missing values, but overall a lot of progress was made here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Up\n",
    "\n",
    "Consolidate process to date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
