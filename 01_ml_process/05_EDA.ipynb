{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entry 5 - Explore the Data\n",
    "\n",
    "In <font color='red'>Entry 4</font>, I put together a dataset of information about 11 planetary bodies. Now its time to see what that information tells us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "This is the time to get a feel for the data. The kinds of things I'm looking at are:\n",
    "\n",
    "- Are the variables structured, unstructured, numerical, categorical, etc?\n",
    "- Are there missing values?\n",
    "- What are the distrubutions?\n",
    "- Are there outliers or noise?\n",
    "- How do they relate to each other?\n",
    "- What's the target variable and which are the features?\n",
    "- Are the features possibly useful for predicting the target?\n",
    "- Are there any transformations that would be useful?\n",
    "  - Square\n",
    "  - Square root\n",
    "  - Logrithmic\n",
    "  - Normalization\n",
    "  - Standardization\n",
    "- Is any supplementary data needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Options\n",
    "\n",
    "There are a lot of ways to explore data. Descriptive Statistics and visualization are the two most common methods. Looking at the data in a chart can reveal trends that are invisible when looking at descriptive statistics (as demonstrated by [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)). But descriptive statistics also have their place.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Descriptive statisics include:</b>\n",
    "            <ul>\n",
    "                <li>Max</li>\n",
    "                <li>Min</li>\n",
    "                <li>Range</li>\n",
    "                <li>Mean</li>\n",
    "                <li>Median</li>\n",
    "                <li>Mode</li>\n",
    "                <li>Standard deviation</li>\n",
    "                <li>Variance</li>\n",
    "                <li>Quartiles</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "        <td><b>Visualization options include:</b>\n",
    "            <ul>\n",
    "                <li>Bar charts</li>\n",
    "                <li> Line charts</li>\n",
    "                <li>Area charts</li>\n",
    "                <li>Scatter plots</li>\n",
    "                <li>Bubble plots</li>\n",
    "                <li>Box and violin plots</li>\n",
    "                <li>Heatmaps</li>\n",
    "                <li>Treemaps</li>\n",
    "                <li>Histographs and density plots</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "### Visualization resources:\n",
    "\n",
    "- [From Data to Viz](https://www.data-to-viz.com/)\n",
    "- [Data Visualization Society](https://www.datavisualizationsociety.com/challenge)\n",
    "- [Makeover Monday](https://www.makeovermonday.co.uk/)\n",
    "- [Seaborn](https://seaborn.pydata.org/tutorial.html)\n",
    "- [Bokeh](https://docs.bokeh.org/en/latest/index.html)\n",
    "- [Matplotlib](https://matplotlib.org/contents.html)\n",
    "- [Plotly](https://plot.ly/python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Proposed Solution\n",
    "\n",
    "The full code and visuals for the below are all in the supplementary jupyternotebook: <font color='red'>5_visualizations.ipynb.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at non-null entries\n",
    "\n",
    "First I used .info() to look at the count of non-null entries. A non-null count lower than the number of entries indicates missing values. Missing values were one of those things I talked about in <font color='red'>Entry 2</font>. They cause some machine learning algorithms to choke.\n",
    "\n",
    "The planets dataset has no missing values. Of course, I curated this very small dataset by hand and made sure there were no missing values. I'll deal with missing values and the different ways to deal with it in another entry.\n",
    "\n",
    "#### Review variable types\n",
    "\n",
    "The .info() method also gives information about the datatype. I like looking at this because just because I think it's one kind of variable doesn't necessarily mean it loaded that way. I've had a numeric column load as a string because a value like 'None' was entered. Double checking small things like this can save a lot of time further down the line.\n",
    "\n",
    "There are 3 non-numeric columns: type, rings, and magnetic_field. The rest are numeric ([float or int](https://realpython.com/python-data-types/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive Statistics\n",
    "\n",
    "Next I take a glance at the descriptive statistics. The fastest way to get some basic descriptive statistics is to use .describe().  This also shows the count, but includes other useful information like the mean, standard deviation, min, max, and the 25/50/75 quartiles for numeric data. This information is useful to determine what kind of data pre-processing will be needed. Pre-processing will be covered in another entry, but some examples include:\n",
    "\n",
    "- Scaling\n",
    "- Normalization\n",
    "- Selection\n",
    "- Transformations\n",
    "- Aggregation\n",
    "- Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations\n",
    "\n",
    "I started with a pairplot of all the numeric data (hint, pairplot generally only plots the numeric values). That took several minutes to run (the more variables there are the longer it takes to generate the plot) and gave me a 23 x 23 gridplot.\n",
    "\n",
    "That's a lot of plots. They were tiny and the text was so small it was unreadable.\n",
    "\n",
    "I narrowed down the features to just what seemed unique and relevant. That left me with eight features, which gave me an 8x8 grid (64 plots). From these, I created iterations of different combinations of features, but mainly focused on how the features related to atmospheric mass.\n",
    "\n",
    "#### Disclaimer\n",
    "\n",
    "This problem is interesting in that I'm interested in atmospheric mass, but I'll be predicting a range of planetary mass based on set values of atmospheric mass. As such, atmospheric mass is my variable of interest, but planetary mass is my target value. Generally, the variable of interest is the one that will be the one that's being predicted on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fail\n",
    "\n",
    "Whittling down features by hand was useful in this case, but doesn't necessarily (or at all) sound like a task I want to do for the nearly 600 features at work. Nor do I want to do this for every Kaggle competition or UCI dataset. On top of that, it's easy to get carried away with visualizations and end up with tens of plots that may or may not say anything about pertinent relationships.\n",
    "\n",
    "For this 11 observation dataset, I ended up with around 22 plots (I counted each pairplot as a single plot instead of including every plot in the grid as its own plot). And that includes having narrowed my focus to 5-8 features after the initial look at the pairplots.\n",
    "\n",
    "Exploring the data is important and can teach me things I didn't know about the data, but what I need is a way to automatically determine feature importance, then concentrate on those features.\n",
    "\n",
    "#### Side note\n",
    "\n",
    "When working on a dataset with a large number of features, like the one I have at work, there is usually feature engineering that goes into creating the features. A lot of exploratory analysis goes into the creation of these features. That is probably where I would expect EDA to occur. Feature engineering is a topic for another series of entries, but as an introduction some examples of feature engineering include:\n",
    "\n",
    "- Counts\n",
    "- Ratios\n",
    "- Simiarities\n",
    "- Mathematical transformations\n",
    "  - Log\n",
    "  - Square\n",
    "  - Exponentiation\n",
    "  - Etc\n",
    "- Aggregations\n",
    "- NLP\n",
    "  - Things as simple as character counts\n",
    "  - Things as complicated as [n-grams](https://en.wikipedia.org/wiki/N-gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Up\n",
    "\n",
    "At this stage in a production pipeline, I'm most interested in how to rank the features and concentrate on just the useful ones.\n",
    "\n",
    "Enter my fantastic co-worker [Sabber](https://medium.com/@sabber). He proposed using correlation to determine important features. Entry 6 will focus on using correlation to narrow focus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
