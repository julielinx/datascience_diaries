{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa10a087-1a51-4042-83d1-4414b6aaba19",
   "metadata": {},
   "source": [
    "# Markdown Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc83e365-1233-4c98-9e19-45dcea2e0742",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Mathematics</b>\n",
    "            <ul>\n",
    "                <li>Statistics</li>\n",
    "                <li>Probability</li>\n",
    "                <li>Linear Algebra</li>\n",
    "                <li>Calculus</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "        <td><b>Databases</b>\n",
    "            <ul>\n",
    "                <li>Infrastructure</li>\n",
    "                <li>SQL</li>\n",
    "                <li>Entity Relationship Modeling</li>\n",
    "                <li>Normalization</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "        <td><b>Technology</b>\n",
    "            <ul>\n",
    "                <li>Version Control</li>\n",
    "                <li>Virtual Environments/Containers</li>\n",
    "                <li>Command Line Interface</li>\n",
    "                <li>Repositories</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Programming</b>\n",
    "            <ul>\n",
    "                <li>Principals and theory</li>\n",
    "                <li>Specific language (Python or R)</li>\n",
    "                <li>Data structures</li>\n",
    "                <li>Algorithms</li>\n",
    "                <li>Regex</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "        <td><b>Data Handling</b>\n",
    "            <ul>\n",
    "                <li>Analysis</li>\n",
    "                <li>Mining</li>\n",
    "                <li>Wrangling/Cleaning</li>\n",
    "                <li>Feature Engineering</li>\n",
    "                <li>Time Series</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "        <td><b>Specialty Areas</b>\n",
    "            <ul>\n",
    "                <li>Graph</li>\n",
    "                <li>Natural Language Processing</li>\n",
    "                <li>Computer Vision</li>\n",
    "                <li>Behavior Analysis</li>\n",
    "                <li>Entity Recognition</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Storytelling</b>\n",
    "            <ul>\n",
    "                <li>Communication</li>\n",
    "                <li>Visualization</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "        <td><b>Big Data</b>\n",
    "            <ul>\n",
    "                <li>Cloud Computing</li>\n",
    "                <li>Streaming vs Batch</li>\n",
    "            </ul>\n",
    "            </td>\n",
    "        <td><b>Domain Knowledge</b>\n",
    "            <ul>\n",
    "                <li>Industry Processes</li>\n",
    "                <li>Opportunities & Challenges</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "#### Specific alignment\n",
    "\n",
    "<table align='left'>\n",
    "    <tr>\n",
    "        <th>Supervision</th>\n",
    "        <th>Prediction types</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Supervised</td>\n",
    "        <td>Regression</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td>Classification</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "#### With math equations\n",
    "\n",
    "<table align='left'>\n",
    "    <tr>\n",
    "        <td><b>Comparison category</b></td>\n",
    "        <td><b>Normal Equation</b></td>\n",
    "        <td><b>Gradient Descent</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Alpha</td>\n",
    "        <td>No need to choose alpha</td>\n",
    "        <td>Need to choose alpha</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Interation</td>\n",
    "        <td>No need to iterate</td>\n",
    "        <td>Needs many iterations</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Computational complexity</td>\n",
    "        <td>$O(n^{3})$ (need to calculate inverse of $X^{T}X$) *</td>\n",
    "        <td>$O(kn^{2})$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Speed with large feature set</td>\n",
    "        <td>Slow if <i>n</i> is very large</td>\n",
    "        <td>Works well when <i>n</i> is large</td>\n",
    "    </tr></table>\n",
    "    \n",
    "#### With images\n",
    "\n",
    "### Examples\n",
    "\n",
    "Here is a table of the name, symbol, dimensions, and data sctructure of the arrays/matrices used in the calculation:\n",
    "\n",
    "<table align='left'>\n",
    "    <tr>\n",
    "        <td><b>Name</b></td>\n",
    "        <td><b>Theta array / alpha / learning rate</b></td>\n",
    "        <td><b>Target array</b></td>\n",
    "        <td><b>Feature matrix</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Symbol</b></td>\n",
    "        <td><b>$\\theta$</b></td>\n",
    "        <td><b>y</b></td>\n",
    "        <td><b>X</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Dimensions</b></td>\n",
    "        <td>(n+1 x 1)</td>\n",
    "        <td>(m x 1)</td>\n",
    "        <td>(m x n+1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Data Structure</b></td>\n",
    "        <td>$\\theta = \\begin{bmatrix}\n",
    "    \\theta_{0} \\\\\n",
    "    \\theta_{1} \\\\\n",
    "    \\theta_{2} \\\\\n",
    "    \\dotsb \\\\\n",
    "    \\theta_{n}\n",
    "    \\end{bmatrix}$</td>\n",
    "        <td>$y = \\begin{bmatrix}\n",
    "    y_{1} \\\\\n",
    "    y_{2} \\\\\n",
    "    y_{3} \\\\\n",
    "    \\dotsb \\\\\n",
    "    y_{m}\n",
    "    \\end{bmatrix}$</td>\n",
    "        <td>$X = \\begin{bmatrix}\n",
    "    1 & x_{1}^{1} & x_{2}^{1} & \\dotsb & x_{n}^{1}\\\\\n",
    "    1 & x_{1}^{2} & x_{2}^{2} & \\dotsb & x_{n}^{2} \\\\\n",
    "    1 & x_{1}^{3} & x_{2}^{3} & \\dotsb & x_{n}^{3} \\\\\n",
    "    \\dotsb & \\dotsb & \\dotsb & \\dotsb & \\dotsb \\\\\n",
    "    1 & x_{1}^{m} & x_{2}^{m} & \\dotsb & x_{n}^{m}\n",
    "    \\end{bmatrix}$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Structure pic</b></td>\n",
    "        <td><img src='../../img/gd_theta_array.jpg' width=\"209\" height=\"250\"/></td>\n",
    "        <td><img src='../../img/gd_target_array.jpg' width=\"201\" height=\"250\"/></td>\n",
    "        <td><img src='../../img/gd_matrix.jpg' width=\"343\" height=\"250\"/></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ad7b0-c088-400a-9ba8-a24a3b4743a3",
   "metadata": {},
   "source": [
    "## Images\n",
    "\n",
    "#### Jupyter reference\n",
    "\n",
    "![data science books](https://raw.githubusercontent.com/julielinx/datascience_diaries/master/img/ds_books_web.jpg)\n",
    "\n",
    "#### HTML link and caption\n",
    "\n",
    "<figure>\n",
    "    <img src=\"../img/over_under_fitting.png\" width =600 align=\"center\" />\n",
    "    <figcaption>*Image from <a href=\"https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\">Train/Test Split and Cross Validation in Python</a>*</figcaption>\n",
    "</figure>\n",
    "\n",
    "#### Set size\n",
    "\n",
    "<img src=\"https://hsto.org/webt/n0/dg/du/n0dgduav1ygc3iylumtwjcn15mu.png\" width=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d81b97-7d6c-4e67-8de3-6d9d07531c45",
   "metadata": {},
   "source": [
    "## Quote / indentation\n",
    "\n",
    "[Introduction to Machine Learning with Python](https://www.amazon.com/Introduction-Machine-Learning-Python-Scientists/dp/1449369413) points out on page 34 that\n",
    "\n",
    "> Any intuition derived from datasets with few features (also called *low-dimensional* datasets) might not hold in datasets with many features (*high-dimensional* datasets). As long as you keep that in mind, inspecting algorithms on low-dimensional datasets can be very instructive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c979fa2-6bbf-4401-b46e-4460185ce3c6",
   "metadata": {},
   "source": [
    "## Bulletted list\n",
    "\n",
    "### Supervised learning\n",
    "- Regression\n",
    "  - Linear regression\n",
    "    - Ordinary least squares regression (OLSR)\n",
    "      - Normal Equation\n",
    "      - Gradient Descent\n",
    "  - Regularization algorithms\n",
    "    - Least absolute shrinkage and selection operator (LASSO)\n",
    "    - Ridge regression\n",
    "    - Elastic net\n",
    "  - Logistic regression (\\* the output would group this with classification algorithms. However, the algorithm itself is based on regression with a minor alteration to get binary output, as such, I've put it with the regression algorithms)\n",
    "  - Stepwise regression\n",
    "  - Multivariate adaptive regression splines (MARS)\n",
    "  - Locally estimated scatterplot smoothing (LOESS)\n",
    "  - Polynomial regression\n",
    "  - Polynomials and splines\n",
    "  - Splines\n",
    "- Classification\n",
    "  - Decision trees\n",
    "    - Classification and regression tree (CART)\n",
    "    - Interative dichotomiser 3 (ID3)\n",
    "    - C4.5 and c5.0\n",
    "    - Chi-squared automatic interaction detection (CHAID)\n",
    "    - Decision stump\n",
    "    - M5\n",
    "    - Conditional decision trees\n",
    "  - Ensemble models\n",
    "    - Boosting\n",
    "    - Bagging (Bootstrapped aggregation)\n",
    "    - AdaBoost\n",
    "    - Weighted average (Blending)\n",
    "    - Stacked generalization (Stacking)\n",
    "    - Gradient boosting machines\n",
    "    - Gradient boosted regression trees \n",
    "    - Random forests\n",
    "- Support vector machines\n",
    "- Bayesian\n",
    "  - Naïve bayes\n",
    "  - Gaussian naïve bays\n",
    "  - Multinomial naïve bays\n",
    "  - Average one-dependence estimators (AODE)\n",
    "  - Bayesian belief network (BBN)\n",
    "  - Bayesian network (BN)\n",
    "- Discriminant analysis\n",
    "  - Linear discriminant analysis\n",
    "  - Nonlinear discriminant analysis\n",
    "  - Flexible discriminant analysis\n",
    "  - Mixture discriminant analysis\n",
    "  - Quadratic discriminant analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6945ea-18b3-478d-b0b3-04113b7fa5d6",
   "metadata": {},
   "source": [
    "## References / Examples\n",
    "\n",
    "- [Entry 2 - Define the Process](https://github.com/julielinx/datascience_diaries/blob/master/01_ml_process/02_define_process.ipynb)\n",
    "- [Entry 17 - Resampling](https://github.com/julielinx/datascience_diaries/blob/master/02_model_eval/17_resampling.ipynb)\n",
    "- [Entry 32 - Modeling data](https://github.com/julielinx/datascience_diaries/blob/master/03_supervised_learning/32_model_algos.ipynb)\n",
    "- [Entry 36 - Ordinary Least Squares (OLS)](https://github.com/julielinx/datascience_diaries/blob/master/03_supervised_learning/01_regression/36_regression_OLS.ipynb)\n",
    "- [Entry 37b - Gradient Descent](https://github.com/julielinx/datascience_diaries/blob/master/03_supervised_learning/01_regression/37b_regression_gradient_descent.ipynb)\n",
    "- [Entry 50 - Decision Tree Subtypes](https://github.com/julielinx/datascience_diaries/blob/master/03_supervised_learning/02_tree_based/50_trees_subtypes.ipynb)\n",
    "- [Entry 51 - Ensemble Learning](https://github.com/julielinx/datascience_diaries/blob/master/03_supervised_learning/02_tree_based/51_ensembles_models.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
