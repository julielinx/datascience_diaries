{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entry 29 - Lift analysis - Cumulative gains and lift\n",
    "\n",
    "Remember back in <font color='red'>Entry 16</font> when I said I wasn't planning to cover lift? Well, plans change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "Lift charts were in [Applied Predictive Modeling](https://www.amazon.com/Applied-Predictive-Modeling-Max-Kuhn-ebook/dp/B00K15TZU0), so I wanted to include them in my review of metrics. As I was researching lift charts, cumulative gains charts and the Kolomogorov-Smirnov statistic also came up.\n",
    "\n",
    "These metrics look like a good way to evaluate how a model is doing agains the baseline no model/no information rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Options\n",
    "\n",
    "These three charts all order the predictions by their predicted probability of belonging to the positive class in decending order. They are then broken into bins, usually deciles.\n",
    "\n",
    "### Cumulative gains\n",
    "\n",
    "This plots the proportion of all observations in the bin (remember the observations are ordered by likelihood that they belong in the positive class) against the proportion of positive class in the bin. Because it's cumulative, all data in lower deciles are included in higher deciles. Ie, by the 10th declie (100% of the data) the proportion of positive class will be 100%.\n",
    "\n",
    "Basically, in the first 10% of data (the 0 to 0.1 decile, which includes the observations with the highest probability of being in the positive class) there are X observations (ie 10% of all observations). Of those Y are in the positive class, which makes up Z percent of all positive class observations.\n",
    "\n",
    "Now for some numbers to make this more concrete.\n",
    "\n",
    "- I have a dataset of 100 observations (there are 10 observations in each of my bins).\n",
    "- 5 of those observations are in the positive class.\n",
    "- In my full dataset there are 15 positive observations.\n",
    "\n",
    "With the above information, we can see that the first decile holds 30% of the positive class. Within the full dataset the positive class only makes up 15% of my data. As such, the model did 15% better than if I'd used no model.\n",
    "\n",
    "### Lift chart\n",
    "\n",
    "The lift chart works pretty much directly on the cumulative gains data. It shows how much better the model preformed that if no model had been used. For the example above, the lift for the first decile would be 2 because it identified twice as many of the positive class than random guessing would have.\n",
    "\n",
    "### Kolmogorov-Smirnov statistic\n",
    "\n",
    "The Kolmogorov-Smirnov (KS) statistic calculates the difference between the cumulative target and the cumulative non-target (kind of like the residual error, which returns the difference between the mean and the observed value for regression problems (see <font color='red'>Entry 21</font> for more information on residual error)). This difference in value indicates how good the model is at separating the two classes.\n",
    "\n",
    "As noted in [MODEL EVALUATION – CLASSIFICATION MODELS](https://www.datavedas.com/model-evaluation-classification-models/):\n",
    "\n",
    "> A K-S statistic=100 will mean that the model is able to create two mutually exclusive groups with each group having a separate class label of observations. K-S Statistic=0 indicates a very poor model which fails to successfully distinguish between the classes.\n",
    "\n",
    "> For a good model, the maximum K-S statistic should fall in the top three or four deciles as we expect the maximum differentiation [...] to happen in the initial deciles only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Proposed Solution\n",
    "\n",
    "At first I wasn't sure these metrics would be helpful for my use case. Cumulative gains and lift would be okay at showing the value added by using a model. Which would be fine to show upper leadership to quantify the value add of the machine learning team. [Meaningful Metrics: Cumulative Gains and Lyft Charts](https://towardsdatascience.com/meaningful-metrics-cumulative-gains-and-lyft-charts-7aac02fc5c14) points out that the AUC metrics tend to be a little abstract for non-technical managers.\n",
    "\n",
    "However, my department already has a legacy system in place, so I'd have to hack the baseline to be the results of the legacy system. Meh. We already have several metrics we track to show value.\n",
    "\n",
    "Then I got to the KS statistic. For the data at my work, a human has to review each observation before a decision is made on that observation. In these situations, we ony want to tag X% of observations for human review.\n",
    "\n",
    "It's like the churn example given in MODEL EVALUATION – CLASSIFICATION MODELS. If a human has to call each positive prediction (the customers the model thinks are likely to leave the company), then you want to put the customers most likely to churn in front of the humans calling the customers. Same for lead generation (lead generation is when there is a list of potential customers that someone calls to see if that potential customer is interested in a product or service). One person is highly unlikely to get through 100,000 leads in a day. They need to focus on the 10 most likely to pan out and turn into a sale.\n",
    "\n",
    "The KS statistic turns the model's ability to separate the classes into a hard number that can be viewed at different proportions of the total population. If we have the capacity to look at 20% of the total observations, then we can see how well the model is able to different the classes at that percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fail\n",
    "\n",
    "I'm not exactly sure how I'd want to use this, but it's good to have in my back pocket.\n",
    "\n",
    "Okay, so this second point is the opposite of a fail but ... this post only took around 2 hours. I finally met my time goal of 1-2 hours on the first try! (Yes, I'm pretty sure this is the first time that's happened. Yes, I'm aware that this is entry number 29.) I even created three notebooks to go with this that looked at the results on three different datasets.\n",
    "\n",
    "Most of my posts, especially the ones around classification metrics, have been running way longer, and end up getting broken into multiple posts. Even dividing the time spent by the number of posts I end up with probably doesn't get me down to 2 hours per post. So, yay! Finally!\n",
    "\n",
    "Maybe this will be the start of a trend! (I'm totally not holding my breath for that.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- [MODEL EVALUATION – CLASSIFICATION MODELS](https://www.datavedas.com/model-evaluation-classification-models/)\n",
    "- [Cumulative Gains and Lift Charts](http://www2.cs.uregina.ca/~dbd/cs831/notes/lift_chart/lift_chart.html)\n",
    "- [Scikit-plot Documentation](https://readthedocs.org/projects/scikit-plot/downloads/pdf/stable/)\n",
    "- [Meaningful Metrics: Cumulative Gains and Lyft Charts](https://towardsdatascience.com/meaningful-metrics-cumulative-gains-and-lyft-charts-7aac02fc5c14)\n",
    "- [The Lift Curve: Unveiled](https://towardsdatascience.com/the-lift-curve-unveiled-998851147871)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
