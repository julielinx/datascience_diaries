{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entry 19 - Implementing Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "In <font color='red'>Entry 18</font> I finalized the decision to use a hybrid approach to validating models. I will split out a hold-out set, then perform stratified k-fold cross-validation on the training set. Scikit-Learn has a pretty close visual representation of this [hybrid approach](https://scikit-learn.org/stable/modules/cross_validation.html):\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=400>\n",
    "\n",
    "To do this, I must complete the following steps:\n",
    "\n",
    "- Load the data\n",
    "- Split out a test set\n",
    "- Segment the train set into k-folds\n",
    "- Preprocess the train set of each fold\n",
    "- Train the model using the train set of each fold\n",
    "- Return the individual scores for each split\n",
    "- Return the average score for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Options\n",
    "\n",
    "Scikit-Learn has several options obtaining a score using cross-validation. I'll skip the methods I already ruled out (shuffle-split, repeated, etc). The remaining eligible options include:\n",
    "\n",
    "- [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)\n",
    "- [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate)\n",
    "- [cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict)\n",
    "- [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n",
    "- [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)\n",
    "- [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit)\n",
    "\n",
    "### cross_val_score\n",
    "\n",
    "The limitations of this function spawned the need for <font color='red'>Entry 16</font>, basically the Define the Problem entry of this series of entries. The function creates an internal model to determine the predictions and return a score. It is not intended to create a model which will then be applied to predict the value of new observations. \n",
    "\n",
    "In addition to the above problems, this function only returns a single metric at a time. I'm interested in looking at all the metrics listed in <font color='red'>Entry 16</font>.\n",
    "\n",
    "It does allow preprocessing to be incorporated into the process via the pipeline module. As discussed in The Fail section of <font color='red'>Entry 17</font>, preprocessing on the full training set prior to splitting the data introduces data leakage.\n",
    "\n",
    "### cross_validate\n",
    "\n",
    "This function addresses one of the major failings of cross_val_score, it will return multiple metrics. It can be configured to return the scores from the training data as well as the testing data.\n",
    "\n",
    "<font color='red'>Incorporates into Pipeline?</font>\n",
    "\n",
    "### cross_val_predict\n",
    "\n",
    "This function returns the prediction for each observation from when it was assigned to the test set. Due to this unique return, it can only be used with cross-validation methods that assign an observation to the test set exactly once (ie k-fold. Not repeated, bootstrap, or shuffle).\n",
    "\n",
    "Scikit-Learning includes a warning concerning the use of this function: 'cross_val_predict simply returns the labels (or probabilities) from several distinct models undistinguished. Thus, cross_val_predict is not an appropriate measure of generalisation error.'\n",
    "\n",
    "This function is only recommended for two types of situation:\n",
    "\n",
    "- Visualization of predictions obtained from different models\n",
    "- Model blending: When predictions of one supervised estimator are used to train another estimator in ensemble methods\n",
    "\n",
    "### KFold\n",
    "\n",
    "This is the base function to split a dataset into k-folds. It allows for more control of the splitting process than the three generic functions above. It can be used in conjunction with the above functions by assigning the output of KFold to a variable, then using that variable in the 'cv' parameter in the cross_val_score, cross_validate, or cross_val_predict function.\n",
    "\n",
    "### StratifiedKFold\n",
    "\n",
    "This is the same basic function as KFold, but which stratifies the folds.\n",
    "\n",
    "### TimeSeriesSplit\n",
    "\n",
    "This function takes into account something that I haven't addressed yet, the correlation between observations that are close together in time. The stock market is a straight forward example of when time needs to be taken into account. The observation of one day depends, at least in some part, on the observation of the prior day. For the stock market, the stock price at the end of day 1 sets the start price on day 2.\n",
    "\n",
    "This can also be seen for behavioral trends, especially the kinds of behavior that adapt to changes. For example, if a website changes their layout, customer behavior will adapt to the changes which will necessarility change the way a model predicts behavior.\n",
    "\n",
    "I'm going to leave this out of consideration for now, because I'd like to explore time series and it's effects more closely in another series of entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Proposed Solution\n",
    "\n",
    "For most classification problems I work on, stratifiedKFold with shuffling seems like the best data splitting method, for regression problems, KFold seems like the obvious choice. The number of splits, per the discussion in <font color='red'>Entry 18</font> the number of splits should be 5 or 10. I'll want to play with these two values once I start running metrics to see which works better for what kind of datasets / data characterists.\n",
    "\n",
    "The cross_validate function looks like the most appropriate solution to return multiple metrics. In the notebook for this entry, I'll just do some standard metrics, then explore each one in depth in later entries.\n",
    "\n",
    "As an alternative, I could use the .split method of KFold or StratifiedKFold to generate indices for the split. Having the indicies would allow me to use cross_val_predict to generate predictions. Once I have the predictions, since I have the indicies, I could run whatever metrics I can calculate on the predictions from each of the splits. The necessity of this approach will depend on whether I can run all the metrics I'm interested in using the parameters in cross_validate.\n",
    "\n",
    "The last piece will be to incorporate a pipeline to allow preprocessing transformations to be completed on the training set of each split. I'll address the pipeline aspect in the next entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fail\n",
    "\n",
    "For some reason the cross_validate function requires the estimator to be a variable, not the actual algorithm function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [3.1. Cross-validation: evaluating estimator performance](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
