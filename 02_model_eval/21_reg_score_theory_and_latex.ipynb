{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entry 21 - Scoring Regression Models - Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "Supervised learning wherein predictions are made tend to come in two flavors. The first is to predict a continuous number (like the price of a house - the predictions would be things like 10,684.54). The second is a class (like whether a customer is likely to purchase a product - yes or no). The prediction depends on the target values. When the target is continuous so is the prediction. When the target is a class, so is the prediction.\n",
    "\n",
    "I need a way to measure a model's preformance. The first aspect of this is to look at measures for continuous targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "\n",
    "There are quite a few terms and concepts that the solutions to this problemare rely on. Since I appreciate when terms are clearly defined instead of left to the imagination, here is a list with definitions and equations.\n",
    "\n",
    "**Symbols**\n",
    "\n",
    "- $y_{i}$ is an observed value\n",
    "- $\\hat{y_{i}}$ is a predicted value\n",
    "- $\\bar{y_{i}}$ is the mean value\n",
    "- $\\mu$ is also the mean value\n",
    "- $n$ is the number of observations\n",
    "- $\\sum$ means to sum things together\n",
    "- | | is to take the absolute value\n",
    "- The rest should be basic mathematical symbols\n",
    "\n",
    "**Bias and Variance**\n",
    "\n",
    "*[Hands-On Machine Learning](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291)* has a very succinct sidebar with information on bias, variance, and irreducible error. These are the three components that make up a model's generalization error.\n",
    "\n",
    "> *Bias*</br>\n",
    "This part of the generalization error is due to wrong assumptions, such as assuming that the data is linear when it is actually quadratic. A high-bias model is most likely to underfit the training data.</br></br>\n",
    "*Variance*</br>\n",
    "This part is due to the mode's excessive sensitivity to small variations in the training data. A model with many degrees of freedom (such as a high-degree polynomial model) is likely to have high variance, and thus to overfit the training data.</br></br>\n",
    "*Irreducible error*</br>\n",
    "This part is due to the noisiness of the data itself. The only way to reduce this part of the error is to clean up the data (e.g., fix the data sources, such as broken sensors, or detect and remove outliers).\n",
    "\n",
    "**Bias**\n",
    "\n",
    "Bias is the difference between the expected value and the true value.\n",
    "\n",
    "**Variance**\n",
    "\n",
    "Variance measures how far a set of numbers are spread out from their average value. The formal definition is: the average of the squared differences from the mean.\n",
    "\n",
    "$Var = \\frac{\\sum{(x - \\mu)}^2}{n}$\n",
    "\n",
    "**Residuals**\n",
    "\n",
    "Also called **error**. Residuals quantify how far off a prediction was from the actual value. If the value is 0 the prediction matched the observed value perfectly. There is no minimum or maximum range. The larger the value, the further the prediction is from the actual value.\n",
    "\n",
    "The formula is the observed value minus the predicted value:\n",
    "\n",
    "$e = y_{i} - \\hat{y_{i}}$\n",
    "\n",
    "Keep in mind that the impact of how large this number is depends on the variance of the underlying data. For house prices that range from \\$100,000 to \\$10,000,000 a residual of 10,000 would be considered good. However, for a bottle of soap where the prices range from \\$0.99 to \\$20.49, a residual of 10,000 would be a really bad prediction.\n",
    "\n",
    "**Absolute Error**\n",
    "\n",
    "Technically, the difference between a residual and an error is that residuals are the difference between the observed value and the predicted value, whereas errors are the difference between the observed value and the *true* value. (See [Errors and residuals](https://en.wikipedia.org/wiki/Errors_and_residuals) on Wikipedia, the answers to [this StackExchange](https://stats.stackexchange.com/questions/133389/what-is-the-difference-between-errors-and-residuals) question, and the definition of [Mean Absolute Error](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_525) on Springer Link.)\n",
    "\n",
    "According to one of the answers on StackExchange: \"Error term is a theoretical concept that can never be observed, but the residual is a real world value[...].\"\n",
    "\n",
    "The practical use of the absolute error in machine learning is:\n",
    "\n",
    "$absolute\\text{ }error = | y_{i} - \\hat{y_{i}} |$\n",
    "\n",
    "**Squared Error**\n",
    "\n",
    "$squared\\text{ }error = (y_{i} - \\hat{y_{i}})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Options\n",
    "\n",
    "While the three definitions above (residuals, absolute error, and squared error) applied to each individual prediction, there are other methods that measure a model's overall performance. These methods include:\n",
    "\n",
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "This sums the absolute errors of all predictions and divides by the number of observations (or multiplies by the reciprical of the number of observations).\n",
    "\n",
    "$MAE = \\frac{\\sum | y_{i} - \\hat{y_{i}} |}{n} = \\frac{1}{n} \\sum | y_{i} - \\hat{y_{i}} |$\n",
    "\n",
    "### Sum of Squared Errors (SSE)\n",
    "\n",
    "[Also known as](https://en.wikipedia.org/wiki/Residual_sum_of_squares) the residual sum of squares (RSS) and the sum of squared residuals (SSR). This is just adding up the squared errors for all the predictions.\n",
    "\n",
    "$SSE = \\sum (y_{i} - \\hat{y_{i}})^2$\n",
    "\n",
    "### Mean Squared Error (MSE)\n",
    "\n",
    "This basically takes the sum of squared erros and divides by the number of observations (or multiplies by the reciprical of the number of observations) to give the mean.\n",
    "\n",
    "$MSE = \\frac{\\sum (y_{i} - \\hat{y_{i}})^2}{n} = \\frac{1}{n} \\sum (y_{i} - \\hat{y_{i}})^2$\n",
    "\n",
    "### Root Mean Squared Error (RMSE)\n",
    "\n",
    "By now I can guess that this is just the square root of the MSE, but I looked it up just to be safe (pg 37 of *Hands-On Machine Learning*). The purpose of taking the square root of the MSE is to put the result back into the same units as the original data (*Applied Predictive Modeling* pg 95).\n",
    "\n",
    "$RMSE = \\sqrt{\\frac{1}{n} \\sum (y_{i} - \\hat{y_{i}})^2}$\n",
    "\n",
    "### $R^2$ or coefficient of determination\n",
    "\n",
    "> Proportion of the information in the data explained by the model\n",
    "<div style=\"text-align:center\">~<em><a href ='http://appliedpredictivemodeling.com/'>Applied Predictive Modeling</a></em> page 95</div>\n",
    "\n",
    "- There are [multiple ways](https://en.wikipedia.org/wiki/Coefficient_of_determination) to calculate $R^2$, but the one used by Scikit-Learn is:\n",
    "\n",
    "$R^2 = 1 - \\frac{\\sum{(y_{i} - \\hat{y_{i}})^2}}{\\sum{(y_{i} - \\bar{y_{i}})^2}}$\n",
    "\n",
    "An easier to read version is:\n",
    "\n",
    "$R^2 = \\frac{MSE}{Var_{yactual}}$\n",
    "\n",
    "- Range of values is generally 0 - 1, but [values outside this range can occur](https://en.wikipedia.org/wiki/Coefficient_of_determination#Interpretation)\n",
    "  - A value of 1 means the predictions explain the data perfectly (predictions match the observations)\n",
    "  - A value of 0 means the predictions explain none of the variability of the data\n",
    "  - Negative values indicate the mean of the data provides a better fit to the outcomes than the predicted values \n",
    "- Cavets\n",
    ">[...] the practitioner must remember that $R^2$ is a measure of correlation, not accuracy</br>\n",
    "$R^2$ is dependent on the variation in the outcome\n",
    "<div style=\"text-align:center\">~<em>Applied Predictive Modeling</a></em> page 96</div>\n",
    "\n",
    "### Explained variance\n",
    "\n",
    "$explained\\text{ }variance = 1 - \\frac{Var(y - \\hat{y})}{Var(y)}$\n",
    "\n",
    "Where $Var(y-\\hat{y}) = \\frac{\\sum{(error^2)} - mean(error)}{n}$\n",
    "\n",
    "According to [this StackExchange answer](https://stats.stackexchange.com/questions/210168/what-is-the-difference-between-r2-and-variance-score-in-scikit-learn) the only difference between $R^2$ and explained variance is the mean(error). So if the mean(error) is 0, explained variance and $R^2$ will be the same. A more thorough answer can also be found on [StackOverflow](https://stackoverflow.com/questions/24378176/python-sci-kit-learn-metrics-difference-between-r2-score-and-explained-varian)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Proposed Solution\n",
    "\n",
    "RMSE and $R^2$ are the most popular measures according to *Applied Predictive Modeling* and *Hands-On Machine Learning*. In the spirit of getting a better intuitive understanding of the metrics, I'm going to run all of them and see what they tell me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fail\n",
    "\n",
    "The number of books and websites I had to go through to cobble together all this information was ridiculous. I expected it all to be in one place. Part of the problem was that most of the books I own spend more time on classification metrics. Part was that I didn't remember things that the authors took for granted (thus the Concepts section). Yet another part was that the notation varied in some books. For example, the authors of *[The Elements of Statistical Learning](https://www.amazon.com/Elements-Statistical-Learning-Prediction-Statistics/dp/0387848576)* obviously love mathematics way more than I do.\n",
    "\n",
    "Getting better at reading math equations is a hurdle I'm going to have to tackle at some point. Eventually I should be able to read a change in notation without having to dig through the internet. All of which sounds like a great, extended, broken out by subject, topic for another (advanced) series of entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "Regression metrics - implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- [Applied Predictive Modeling](https://www.amazon.com/Applied-Predictive-Modeling-Max-Kuhn-ebook/dp/B00K15TZU0)\n",
    "- [Hands-On Machine Learning with Scikit-Learn & TensorFlow](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291)\n",
    "- [The Elements of Statistical Learning](https://www.amazon.com/Elements-Statistical-Learning-Prediction-Statistics/dp/0387848576)\n",
    "- [Errors and residuals](https://en.wikipedia.org/wiki/Errors_and_residuals)\n",
    "- [What is the difference between errors and residuals?](https://stats.stackexchange.com/questions/133389/what-is-the-difference-between-errors-and-residuals)\n",
    "- [Mean Absolute Error](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_525)\n",
    "- [Bias of an estimator](https://en.wikipedia.org/wiki/Bias_of_an_estimator)\n",
    "- [Variance](https://en.wikipedia.org/wiki/Variance)\n",
    "- [Standard Deviation and Variance](https://www.mathsisfun.com/data/standard-deviation.html)\n",
    "- [Residual sum of squares](https://en.wikipedia.org/wiki/Residual_sum_of_squares)\n",
    "- [Coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination)\n",
    "- [What is the difference between 𝑅2 and variance score in Scikit-learn?](https://stats.stackexchange.com/questions/210168/what-is-the-difference-between-r2-and-variance-score-in-scikit-learn)\n",
    "- [Python sci-kit learn (metrics): difference between r2_score and explained_variance_score?](https://stackoverflow.com/questions/24378176/python-sci-kit-learn-metrics-difference-between-r2-score-and-explained-varian)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
